{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of crnn_merge_to_DNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mR2TvAiGQilA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "574964ee-834a-48c1-80f2-31e34d8409ca"
      },
      "source": [
        "%pip install keras_self_attention\n",
        "%pip install keras-tuner"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras_self_attention\n",
            "  Downloading https://files.pythonhosted.org/packages/c3/34/e21dc6adcdab2be03781bde78c6c5d2b2136d35a1dd3e692d7e160ba062a/keras-self-attention-0.49.0.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras_self_attention) (1.19.5)\n",
            "Requirement already satisfied: Keras in /usr/local/lib/python3.7/dist-packages (from keras_self_attention) (2.4.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from Keras->keras_self_attention) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from Keras->keras_self_attention) (1.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from Keras->keras_self_attention) (2.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py->Keras->keras_self_attention) (1.15.0)\n",
            "Building wheels for collected packages: keras-self-attention\n",
            "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-self-attention: filename=keras_self_attention-0.49.0-cp37-none-any.whl size=19468 sha256=63f80c5f365385f31dba2d9e03c1fa4dd7d36633b2345ddb6496dfef84ec8aab\n",
            "  Stored in directory: /root/.cache/pip/wheels/6f/9d/c5/26693a5092d9313daeae94db04818fc0a2b7a48ea381989f34\n",
            "Successfully built keras-self-attention\n",
            "Installing collected packages: keras-self-attention\n",
            "Successfully installed keras-self-attention-0.49.0\n",
            "Collecting keras-tuner\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/ec/1ef246787174b1e2bb591c95f29d3c1310070cad877824f907faba3dade9/keras-tuner-1.0.2.tar.gz (62kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 7.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (20.9)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.19.5)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (0.8.9)\n",
            "Collecting terminaltables\n",
            "  Downloading https://files.pythonhosted.org/packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.23.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (0.22.2.post1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->keras-tuner) (2.4.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2020.12.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->keras-tuner) (1.0.1)\n",
            "Building wheels for collected packages: keras-tuner, terminaltables\n",
            "  Building wheel for keras-tuner (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-tuner: filename=keras_tuner-1.0.2-cp37-none-any.whl size=78938 sha256=19849257f3c3e79a44c42799b74a4d3986764c4a56674deee8d206dffb78ea4a\n",
            "  Stored in directory: /root/.cache/pip/wheels/bb/a1/8a/7c3de0efb3707a1701b36ebbfdbc4e67aedf6d4943a1f463d6\n",
            "  Building wheel for terminaltables (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for terminaltables: filename=terminaltables-3.1.0-cp37-none-any.whl size=15356 sha256=f194d87bbf769390e02d73aeb2abd13f4e28c12afa7bb489c1946575a56039a8\n",
            "  Stored in directory: /root/.cache/pip/wheels/30/6b/50/6c75775b681fb36cdfac7f19799888ef9d8813aff9e379663e\n",
            "Successfully built keras-tuner terminaltables\n",
            "Installing collected packages: terminaltables, colorama, keras-tuner\n",
            "Successfully installed colorama-0.4.4 keras-tuner-1.0.2 terminaltables-3.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWN1YdD7Qvc2"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, load_model, Model\n",
        "from tensorflow.keras.layers import BatchNormalization, Dense, LeakyReLU, Dropout\n",
        "from keras_self_attention import SeqSelfAttention, SeqWeightedAttention\n",
        "import site\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmcD3FuxQw7Q"
      },
      "source": [
        "pd.set_option('display.width', 400)\n",
        "pd.set_option('display.max_columns', 40)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfyld79IQ0j0"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import h5py as h5\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Model\n",
        "import errno\n",
        "import os\n",
        "from collections import defaultdict\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
        "from tensorflow.summary import create_file_writer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import kerastuner as kt\n",
        "from kerastuner import HyperModel\n",
        "import numpy as np\n",
        "import itertools\n",
        "import multiprocessing\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, load_model, Model\n",
        "from tensorflow.keras.layers import BatchNormalization, Dense, LeakyReLU, Dropout\n",
        "from keras_self_attention import SeqSelfAttention, SeqWeightedAttention\n",
        "import site\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import os\n",
        "pd.set_option('display.width', 400)\n",
        "pd.set_option('display.max_columns', 40)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DZ2zSmhRDJf"
      },
      "source": [
        "def get_features_model(model_name, combined_models):\n",
        "    for ids, models in combined_models:\n",
        "        if models[0].name == model_name:\n",
        "            return models[1]\n",
        "    return None\n",
        "\n",
        "def get_features_from_combined_models(combined_models, X_input):\n",
        "    data_features = []\n",
        "    for ids, models in combined_models:\n",
        "        data_features.append(np.array(models[1].predict(X_input), dtype='float64'))\n",
        "    return np.concatenate(tuple(data_features), axis=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nn8uaSm8Cjzv"
      },
      "source": [
        "def coShuffled_vectors(X, Y):\n",
        "    if tf.shape(X)[0] == tf.shape(Y)[0]:\n",
        "        test_idxs = tf.range(start=0, limit=tf.shape(X)[0], dtype=tf.int32)\n",
        "        shuffled_test_idxs = tf.random.shuffle(test_idxs)\n",
        "        return (tf.gather(X, shuffled_test_idxs), tf.gather(Y, shuffled_test_idxs))\n",
        "    else:\n",
        "        raise ValueError(f\"0-dimension has to be the same {tf.shape(X)[0]} != {tf.shape(Y)[0]}\")\n",
        "\n",
        "\n",
        "def getNpArrayFromH5(hf_Data):\n",
        "    X_train = hf_Data['Train_Data']  # Get train set\n",
        "    X_train = np.array(X_train)\n",
        "    Y_train = hf_Data['Label']  # Get train label\n",
        "    Y_train = np.array(Y_train)\n",
        "    return X_train, Y_train\n",
        "\n",
        "# data extraction\n",
        "def getData(is500=True, shuffle=False, ise2e=False, include_secondary=False, validation_split=None, isColab=False):\n",
        "    if not include_secondary:\n",
        "        hf_Train = h5.File(\n",
        "            f'./{\"data\" if not isColab else \"drive/MyDrive/data_papers/ncRNA\"}/{\"e2e_Train_Data\" if ise2e else \"Fold_10_Train_Data\"}_{str(500) if is500 else str(1000)}.h5', 'r')\n",
        "        hf_Test = h5.File(\n",
        "            f'./{\"data\" if not isColab else \"drive/MyDrive/data_papers/ncRNA\"}/{\"e2e_Test_Data\" if ise2e else \"Fold_10_Test_Data\"}_{str(500) if is500 else str(1000)}.h5', 'r')\n",
        "    else:\n",
        "        hf_Train = h5.File(f'./{\"data\" if not isColab else \"drive/MyDrive/data_papers/ncRNA\"}/e2e_Train_Secondary_Data_1136.h5', 'r')\n",
        "        hf_Test = h5.File(f'./{\"data\" if not isColab else \"drive/MyDrive/data_papers/ncRNA\"}/e2e_Test_Secondary_Data_1136.h5', 'r')\n",
        "\n",
        "    X_train, Y_train = getNpArrayFromH5(hf_Train)\n",
        "    X_test, Y_test = getNpArrayFromH5(hf_Test)\n",
        "    Y_train = to_categorical(Y_train, 13)  # Process the label of tain\n",
        "    Y_test = to_categorical(Y_test, 13)  # Process the label of te\n",
        "\n",
        "    if shuffle:\n",
        "        X_train, Y_train = coShuffled_vectors(X_train, Y_train)\n",
        "        X_test, Y_test = coShuffled_vectors(X_test, Y_test)\n",
        "\n",
        "    X_validation = Y_validation = None\n",
        "    if validation_split is not None:\n",
        "        # sklearn split shuffles anyway\n",
        "        X_train, X_validation, Y_train, Y_validation = train_test_split(X_train, Y_train, test_size=validation_split)\n",
        "\n",
        "    return X_train, Y_train, X_test, Y_test, X_validation, Y_validation\n",
        "\n",
        "\n",
        "def getE2eData(is500=True, shuffle=False, include_secondary=False, isColab=False):\n",
        "    if not include_secondary:\n",
        "        hf_Train = h5.File(\n",
        "            f'./{\"data\" if not isColab else \"drive/MyDrive/data_papers/ncRNA\"}/e2e_Train_Data_{str(500) if is500 else str(1000)}.h5', 'r')\n",
        "        hf_Test = h5.File(\n",
        "            f'./{\"data\" if not isColab else \"drive/MyDrive/data_papers/ncRNA\"}/e2e_Test_Data_{str(500) if is500 else str(1000)}.h5', 'r')\n",
        "    else:\n",
        "        hf_Train = h5.File(f'./{\"data\" if not isColab else \"drive/MyDrive/data_papers/ncRNA\"}/e2e_Train_Secondary_Data_1136.h5', 'r')\n",
        "        hf_Test = h5.File(f'./{\"data\" if not isColab else \"drive/MyDrive/data_papers/ncRNA\"}/e2e_Test_Secondary_Data_1136.h5', 'r')\n",
        "\n",
        "    X_train, Y_train = getNpArrayFromH5(hf_Train)\n",
        "    X_test, Y_test = getNpArrayFromH5(hf_Test)\n",
        "    Y_train = to_categorical(Y_train, 13)  # Process the label of tain\n",
        "    Y_test = to_categorical(Y_test, 13)  # Process the label of te\n",
        "\n",
        "    if shuffle:\n",
        "        X_train, Y_train = coShuffled_vectors(X_train, Y_train)\n",
        "        X_test, Y_test = coShuffled_vectors(X_test, Y_test)\n",
        "\n",
        "    hf_Val = h5.File(f'./{\"data\" if not isColab else \"drive/MyDrive/data_papers/ncRNA\"}/e2e_Val_Secondary_Data_1136.h5', 'r') if include_secondary else h5.File(\n",
        "        f'./{\"data\" if not isColab else \"drive/MyDrive/data_papers/ncRNA\"}/e2e_Val_Data_{str(500) if is500 else str(1000)}.h5', 'r')\n",
        "    X_validation, Y_validation = getNpArrayFromH5(hf_Val)\n",
        "    Y_validation = to_categorical(Y_validation, 13)  # Process the label of tain\n",
        "\n",
        "    return X_train, Y_train, X_test, Y_test, X_validation, Y_validation\n",
        "\n",
        "\n",
        "def getE2eDataJustSecondary(shuffle=False,isColab=False):\n",
        "    hf_Train = h5.File(f'./{\"data\" if not isColab else \"drive/MyDrive/data_papers/ncRNA\"}/e2e_Train_just_Secondary_Data_1000.h5', 'r')\n",
        "    hf_Test = h5.File(f'./{\"data\" if not isColab else \"drive/MyDrive/data_papers/ncRNA\"}/e2e_Test_just_Secondary_Data_1000.h5', 'r')\n",
        "\n",
        "    X_train, Y_train = getNpArrayFromH5(hf_Train)\n",
        "    X_test, Y_test = getNpArrayFromH5(hf_Test)\n",
        "    Y_train = to_categorical(Y_train, 13)  # Process the label of tain\n",
        "    Y_test = to_categorical(Y_test, 13)  # Process the label of te\n",
        "\n",
        "    if shuffle:\n",
        "        X_train, Y_train = coShuffled_vectors(X_train, Y_train)\n",
        "        X_test, Y_test = coShuffled_vectors(X_test, Y_test)\n",
        "\n",
        "    hf_Val = h5.File(f'./{\"data\" if not isColab else \"drive/MyDrive/data_papers/ncRNA\"}/e2e_Val_just_Secondary_Data_1000.h5', 'r')\n",
        "    \n",
        "    X_validation, Y_validation = getNpArrayFromH5(hf_Val)\n",
        "    Y_validation = to_categorical(Y_validation, 13)  # Process the label of tain\n",
        "\n",
        "    return X_train, Y_train, X_test, Y_test, X_validation, Y_validation\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHCMi9z-xlo-"
      },
      "source": [
        "def reverse_one_hot(Y_input):\n",
        "    return np.apply_along_axis(np.argmax, 1, Y_input) + 1\n",
        "\n",
        "def plot_history(history):\n",
        "    acc_keys = [k for k in history.history.keys() if k in ('accuracy', 'val_accuracy')]\n",
        "    loss_keys = [k for k in history.history.keys() if not k in acc_keys]\n",
        "    for k, v in history.history.items():\n",
        "        if k in acc_keys:\n",
        "            plt.figure(1)\n",
        "            plt.plot(v)\n",
        "        else:\n",
        "            plt.figure(2)\n",
        "            plt.plot(v)\n",
        "    plt.figure(1)\n",
        "    plt.title('Accuracy vs. epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(acc_keys, loc='lower right')\n",
        "    plt.figure(2)\n",
        "    plt.title('Loss vs. epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(loss_keys, loc='upper right')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def get_layer_by_name(layers, name, return_first=True):\n",
        "    matching_named_layers = [l for l in layers if l.name == name]\n",
        "    if not matching_named_layers:\n",
        "        return None\n",
        "    return matching_named_layers[0] if return_first else matching_named_layers\n",
        "\n",
        "\n",
        "def make_dir_if_not_exist(used_path):\n",
        "    if not os.path.isdir(used_path):\n",
        "        try:\n",
        "            os.mkdir(used_path)\n",
        "        except OSError as exc:\n",
        "            if exc.errno != errno.EEXIST:\n",
        "                raise exc\n",
        "            else:\n",
        "                raise ValueError(f'{used_path} directoy cannot be created because its parent directory does not exist.')\n",
        "\n",
        "\n",
        "def source_model(model_func, model_name, input_shape):\n",
        "    m = None\n",
        "    if isinstance(model_func, tf.keras.models.Model):\n",
        "        m = model_func\n",
        "        m._name = model_name\n",
        "    else:\n",
        "        m = model_func(model_name, input_shape)\n",
        "    return m\n",
        "\n",
        "\n",
        "def compile_and_fit_model_with_tb(model_func,\n",
        "                                  model_name,\n",
        "                                  input_shape,\n",
        "                                  X_train,\n",
        "                                  Y_train,\n",
        "                                  save_every_epoch=True,\n",
        "                                  save_final=False,\n",
        "                                  **kwargs):\n",
        "    m = None\n",
        "    if isinstance(model_func, tf.keras.models.Model):\n",
        "        m = model_func\n",
        "        m._name = model_name\n",
        "    else:\n",
        "        m = model_func(model_name, input_shape)\n",
        "    tb_callback = TensorBoard(log_dir=f'{m.name}_logs', histogram_freq=kwargs.pop(\"histogram_freq\", 1))\n",
        "    if save_every_epoch:\n",
        "        tb_callback.append(ModelCheckpoint(f'{m.name}' + '_model_{epoch:03d}_{val_accuracy:0.2f}'))\n",
        "    m.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    history = m.fit(X_train, Y_train, callbacks=[tb_callback], verbose=2, **kwargs)\n",
        "    if save_final:\n",
        "        make_dir_if_not_exist(model_name)\n",
        "        m.save(f\"{m.name}_saved_model_after_fit\")  # Save the model\n",
        "    return (m, history)\n",
        "    # m.save(f\"{m.name}_Tenth_Fold_New_Model_500_8\") #Save the model\n",
        "\n",
        "\n",
        "def compile_and_fit_model(model_func,\n",
        "                          model_name,\n",
        "                          input_shape,\n",
        "                          X_train,\n",
        "                          Y_train,\n",
        "                          save_every_epoch=True,\n",
        "                          save_final=False,\n",
        "                          **kwargs):\n",
        "    m = None\n",
        "    if isinstance(model_func, tf.keras.models.Model):\n",
        "        m = model_func\n",
        "        m._name = model_name\n",
        "    else:\n",
        "        m = model_func(model_name, input_shape)\n",
        "\n",
        "    callbacks_used = []\n",
        "    if save_every_epoch:\n",
        "        callbacks_used.append(ModelCheckpoint(f'{m.name}' + '_model_{epoch:03d}_{val_accuracy:0.2f}'))\n",
        "    m.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    history = m.fit(X_train, Y_train, callbacks=callbacks_used, verbose=2, **kwargs)\n",
        "    if save_final:\n",
        "        make_dir_if_not_exist(model_name)\n",
        "        m.save(f\"{m.name}_saved_model_after_fit\")  # Save the model\n",
        "    return (m, history)\n",
        "\n",
        "\n",
        "def compile_model_and_fit_with_custom_loop(model_func,\n",
        "                                           model_name,\n",
        "                                           input_shape,\n",
        "                                           X_train,\n",
        "                                           Y_train,\n",
        "                                           **kwargs):\n",
        "    make_dir_if_not_exist(model_name)\n",
        "    m = None\n",
        "    if isinstance(model_func, tf.keras.models.Model):\n",
        "        m = model_func\n",
        "        m._name = model_name\n",
        "    else:\n",
        "        m = model_func(model_name, input_shape)\n",
        "\n",
        "    train_writer = create_file_writer(f'{m.name}_logs/train/')\n",
        "    test_writer = create_file_writer(f'{m.name}_logs/test/')\n",
        "    train_step = test_step = 0\n",
        "\n",
        "    acc_metric = tf.keras.metrics.CategoricalAccuracy()\n",
        "    optimizer = tf.keras.optimizers.Adam()\n",
        "    num_epochs = kwargs.get(\"epochs\", 10)\n",
        "\n",
        "    AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "    BATCH_SIZE = kwargs.get(\"batch_size\", 32)\n",
        "    X_test, Y_test = kwargs.get(\"validation_data\", (None, None))\n",
        "    if X_test is None:\n",
        "        raise ValueError(\"Missing X validation data\")\n",
        "    if Y_test is None:\n",
        "        raise ValueError(\"Missing Y validation data\")\n",
        "\n",
        "    train_dataset_tf = tf.data.Dataset.from_tensor_slices((X_train, Y_train))\n",
        "    train_dataset_tf = train_dataset_tf.batch(BATCH_SIZE)\n",
        "    train_dataset_tf = train_dataset_tf.prefetch(AUTOTUNE)\n",
        "\n",
        "    test_dataset_tf = tf.data.Dataset.from_tensor_slices((X_test, Y_test))\n",
        "    test_dataset_tf = train_dataset_tf.batch(BATCH_SIZE)\n",
        "    test_dataset_tf = train_dataset_tf.prefetch(AUTOTUNE)\n",
        "\n",
        "    loss_fn = tf.keras.losses.CategoricalCrossentropy()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # Iterate through training set\n",
        "        for batch_idx, (x, y) in enumerate(train_dataset_tf):\n",
        "            with tf.GradientTape() as tape:\n",
        "                y_pred = m(x, training=True)\n",
        "                loss = loss_fn(y, y_pred)\n",
        "\n",
        "            gradients = tape.gradient(loss, m.trainable_weights)\n",
        "            optimizer.apply_gradients(zip(gradients, m.trainable_weights))\n",
        "            acc_metric.update_state(y, y_pred)\n",
        "\n",
        "            with train_writer.as_default():\n",
        "                tf.summary.scalar(\"Loss\", loss, step=train_step)\n",
        "                tf.summary.scalar(\n",
        "                    \"Accuracy\", acc_metric.result(), step=train_step,\n",
        "                )\n",
        "                train_step += 1\n",
        "        # Reset accuracy in between epochs (and for testing and test)\n",
        "        acc_metric.reset_states()\n",
        "        # Iterate through test set\n",
        "        for batch_idx, (x, y) in enumerate(test_dataset_tf):\n",
        "            y_pred = m(x, training=False)\n",
        "            loss = loss_fn(y, y_pred)\n",
        "            acc_metric.update_state(y, y_pred)\n",
        "            with test_writer.as_default():\n",
        "                tf.summary.scalar(\"Loss\", loss, step=test_step)\n",
        "                tf.summary.scalar(\n",
        "                    \"Accuracy\", acc_metric.result(), step=test_step,\n",
        "                )\n",
        "                test_step += 1\n",
        "\n",
        "        acc_metric.reset_states()  # Reset accuracy in between epochs (and for testing and test)\n",
        "\n",
        "    return m\n",
        "\n",
        "\n",
        "def run_mirrored_strategy(model_func, base_batch_size, nepochs, x_train, y_train, x_test, y_test, **kwargs):\n",
        "    strategy = tf.distribute.MirroredStrategy()\n",
        "    with strategy.scope():\n",
        "        model = model_func()\n",
        "        model.compile(\n",
        "            optimizer=tf.keras.optimizers.Adam(),\n",
        "            loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "            metrics=tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "        )\n",
        "    batch_size_mirr_strat = base_batch_size * strategy.num_replicas_in_sync\n",
        "    history = model.fit(x_train, y_train, epochs=nepochs, batch_size=batch_size_mirr_strat,\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        **kwargs)\n",
        "    return model, history\n",
        "\n",
        "\n",
        "def sparse_setdiff(a1, a2):\n",
        "    a1a = a1.reshape(a1.shape[0], -1)\n",
        "    a2a = a2.reshape(a2.shape[0], -1)\n",
        "    spa2a = [np.where(x)[0].tolist() for x in a2a]\n",
        "    spa1a = [np.where(x)[0].tolist() for x in a1a]\n",
        "    idxs_to_keep = []\n",
        "    for idx, sample in enumerate(spa1a):\n",
        "        try:\n",
        "            spa2a.index(sample)\n",
        "        except ValueError:\n",
        "            # not in list\n",
        "            idxs_to_keep.append(idx)\n",
        "    return a1[idxs_to_keep], idxs_to_keep\n",
        "\n",
        "def get_combined_features_from_models(\n",
        "        to_combine,\n",
        "        X_train, Y_train,\n",
        "        X_test, Y_test,\n",
        "        reverse_one_hot=False,\n",
        "        normalize_X_func=None):\n",
        "    \n",
        "    models = []\n",
        "    models_dict = {}\n",
        "    X_trains_out = []\n",
        "    X_test_out = []\n",
        "    XY_dict = defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: defaultdict(lambda: None))))\n",
        "\n",
        "    models_have_different_inputs = isinstance(Y_train,list)\n",
        "\n",
        "    if reverse_one_hot:\n",
        "        if models_have_different_inputs:\n",
        "            Y_train_new = np.apply_along_axis(np.argmax, 1, Y_train) + 1\n",
        "            Y_test_new = np.apply_along_axis(np.argmax, 1, Y_test) + 1\n",
        "        else:\n",
        "            Y_train_new = [ np.apply_along_axis(np.argmax, 1, y_train) + 1 for y_train in Y_train ]  \n",
        "            Y_test_new = [ np.apply_along_axis(np.argmax, 1, y_test) + 1 for y_test in Y_test ]              \n",
        "    else:\n",
        "        if models_have_different_inputs:\n",
        "            Y_train_new = Y_train.copy()\n",
        "            Y_test_new = Y_test.copy()\n",
        "        else:\n",
        "            Y_train_new = [ y_train.copy() for y_train in Y_train ] \n",
        "            Y_test_new = [ y_test.copy() for y_test in Y_train ] \n",
        "            \n",
        "\n",
        "    extraction_counter =0\n",
        "    for model_file_name, layer_name, kwargs in to_combine:\n",
        "        model_here = None\n",
        "        if isinstance(model_file_name, tf.keras.models.Model):\n",
        "            model_here = model_file_name\n",
        "            model_file_name = model_here.name\n",
        "        else:\n",
        "            if model_file_name in models_dict.keys():\n",
        "                model_here = models_dict[model_file_name]\n",
        "            else:\n",
        "                model_here = tf.keras.models.load_model(model_file_name,\n",
        "                                                        **kwargs) if kwargs is not None else tf.keras.models.load_model \\\n",
        "                    (model_file_name)\n",
        "\n",
        "        features_model = Model(model_here.input,\n",
        "                               get_layer_by_name(model_here.layers, layer_name).output)\n",
        "        \n",
        "        if normalize_X_func is None:\n",
        "            X_trains_out.append(np.array(features_model.predict(X_train if not models_have_different_inputs else X_train[extraction_counter]), dtype='float64'))\n",
        "            X_test_out.append(np.array(features_model.predict(X_test if not models_have_different_inputs else X_test[extraction_counter]), dtype='float64'))\n",
        "        else:\n",
        "            X_trains_out.append(np.array(normalize_X_func(features_model.predict(X_train if not models_have_different_inputs else X_train[extraction_counter])), dtype='float64'))\n",
        "            X_test_out.append(np.array(normalize_X_func(features_model.predict(X_test if not models_have_different_inputs else X_test[extraction_counter])), dtype='float64'))\n",
        "        XY_dict[model_file_name][layer_name]['Train']['X'] = X_trains_out[-1]\n",
        "        XY_dict[model_file_name][layer_name]['Test']['X'] = X_test_out[-1]\n",
        "        XY_dict[model_file_name][layer_name]['Train']['Y'] = Y_train_new\n",
        "        XY_dict[model_file_name][layer_name]['Test']['Y'] = Y_test_new\n",
        "        models.append(((model_file_name, layer_name), (model_here, features_model)))\n",
        "        models_dict[model_file_name] = model_here\n",
        "        extraction_counter += 1\n",
        "\n",
        "    X_train_new = np.concatenate(tuple(X_trains_out), axis=1)\n",
        "    X_test_new = np.concatenate(tuple(X_test_out), axis=1)\n",
        "\n",
        "    data_train = (X_train_new, Y_train_new)\n",
        "    data_test = (X_test_new, Y_test_new)\n",
        "\n",
        "    return models, data_train, data_test, XY_dict\n",
        "\n",
        "class CNNHyperModel(HyperModel):\n",
        "    def __init__(self, model_name, input_shape, num_classes):\n",
        "        self.input_shape = input_shape\n",
        "        self.num_classes = num_classes\n",
        "        self.model_name = model_name\n",
        "\n",
        "    def build(self, hp):\n",
        "        inputs = tf.keras.Input(shape=self.input_shape)\n",
        "        x = inputs\n",
        "\n",
        "        for idx, i in enumerate(range(hp.Int('conv128_blocks_with_normalizations', 1, 6, default=4))):\n",
        "            x = Conv1D(128, 3, padding='same', name=f\"conv1D_128_{idx}\")(x)\n",
        "            if hp.Boolean(f'conv128_has_leaky_relu_{idx}', default=True):\n",
        "                x = LeakyReLU()(x)\n",
        "            if hp.Boolean(f'conv128_has_max_pooling_{idx}', default=True):\n",
        "                x = MaxPooling1D()(x)\n",
        "            if hp.Boolean(f'conv128_has_batchnorm_{idx}', default=True):\n",
        "                x = BatchNormalization()(x)\n",
        "            if hp.Boolean(f'conv128_has_gaussiannoise_{idx}', default=True):\n",
        "                x = GaussianNoise(hp.Float(f'conv128_gaussiannoise_{idx}',\n",
        "                                       min_value=1e-5,\n",
        "                                       max_value=1e1,\n",
        "                                       sampling='LOG',\n",
        "                                       default=0.05\n",
        "                                       ))(x)\n",
        "        for idx, i in enumerate(range(hp.Int('conv256_blocks_with_normalizations', 1, 4, default=2))):\n",
        "            x = Conv1D(256, 3, padding='same', name=f\"conv1D_256_{idx}\")(x)\n",
        "            if hp.Boolean(f'conv256_has_leaky_relu_{idx}', default=True):\n",
        "                x = LeakyReLU()(x)\n",
        "            if hp.Boolean(f'conv256_has_max_pooling_{idx}', default=True):\n",
        "                x = MaxPooling1D()(x)\n",
        "            if hp.Boolean(f'conv256_has_batchnorm_{idx}', default=True):\n",
        "                x = BatchNormalization()(x)\n",
        "            if hp.Boolean(f'conv256_has_gaussiannoise_{idx}', default=True):\n",
        "                x = GaussianNoise(hp.Float(f'conv256_gaussiannoise_{idx}',\n",
        "                                       min_value=1e-5,\n",
        "                                       max_value=1e1,\n",
        "                                       sampling='LOG',\n",
        "                                       default=0.05\n",
        "                                       ))(x)\n",
        "        x = Flatten(name=\"last_flatten\")(x)\n",
        "        for idx, i in enumerate(range(hp.Int('final_dense', 1, 5, default=2))):\n",
        "            x = Dense(units=hp.Choice(f'final_dense_num_nodes_{idx}', values=[16, 32, 64, 128], default=128),\n",
        "                  activation=hp.Choice(f'final_dense_kernel_activation_{idx}',\n",
        "                                       values=['exponential', 'gelu', 'elu', 'relu', 'tanh'], default='relu'),\n",
        "                  kernel_initializer='RandomNormal',\n",
        "                  bias_initializer='zeros',\n",
        "                  name=f\"final_dense_{idx}\")(x)\n",
        "            if hp.Boolean(f'final_dense_has_dropout_{idx}', default=True):\n",
        "                x = Dropout(hp.Float(f'final_dense_dropout_{idx}',\n",
        "                                 min_value=0.05,\n",
        "                                 max_value=0.75,\n",
        "                                 step=0.05,\n",
        "                                 default=0.2\n",
        "                                 ), name=f\"final_dense_dropout_{idx}\")(x)\n",
        "        outputs = Dense(self.num_classes, activation='softmax', name=\"last_softmax\")(x)\n",
        "        model = tf.keras.Model(inputs, outputs, name=self.model_name)\n",
        "        #  m.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "        if hp.Boolean('optimize_adam', default=True):\n",
        "            model.compile(\n",
        "                optimizer=tf.keras.optimizers.Adam(hp.Float('learning_rate', 1e-5, 1e-1, sampling='log')),\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "        else:\n",
        "            model.compile(\n",
        "                optimizer=hp.Choice('final_optimizer',\n",
        "                                    values=['adam', 'SGD', 'RMSprop', 'Adadelta', 'Nadam', 'Adamax', 'Adagrad'],\n",
        "                                    default='adam'),\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "        return model\n",
        "    \n",
        "\n",
        "def reinitialize_weights(model):\n",
        "    for ix, layer in enumerate(model.layers):\n",
        "        if hasattr(model.layers[ix], 'kernel_initializer') and hasattr(model.layers[ix], 'bias_initializer'):\n",
        "            weight_initializer = model.layers[ix].kernel_initializer\n",
        "            bias_initializer = model.layers[ix].bias_initializer\n",
        "    \n",
        "            old_weights, old_biases = model.layers[ix].get_weights()\n",
        "    \n",
        "            model.layers[ix].set_weights([\n",
        "                weight_initializer(shape=old_weights.shape),\n",
        "                bias_initializer(shape=len(old_biases))])            \n",
        "    return model\n",
        "\n",
        "def reverse_tensor(X):\n",
        "    return tf.gather(X, tf.reverse(tf.range(start=0, limit=tf.shape(X)[0], dtype=tf.int32),(0,)) )\n",
        "\n",
        "   \n",
        "def get_confusion_matrix_classification(model, X, Y_true):\n",
        "    y_pred = model.predict(X)\n",
        "    y_true = np.apply_along_axis(np.argmax, 1, Y_true)\n",
        "    y_pred = np.apply_along_axis(np.argmax, 1, y_pred)\n",
        "    return (confusion_matrix(y_true, y_pred), y_pred, y_true)\n",
        "\n",
        "def misclass_perc_to_weight(input_confusion, add_base=True, func=None):\n",
        "    perc_misclassified = 1.0 - np.array([ input_confusion[x,x] for x in np.arange(input_confusion.shape[0]).tolist() ])/input_confusion.sum(axis=1)\n",
        "    \n",
        "    base_val = min(perc_misclassified[perc_misclassified>0.0])\n",
        "    if add_base:        \n",
        "        perc_misclassified = perc_misclassified + base_val\n",
        "    \n",
        "    perc_misclassified = [ x/base_val for x in perc_misclassified]\n",
        "    \n",
        "    return dict([ (idx, func(perc_val)) if func is not None else (idx, perc_val) for idx, perc_val in enumerate(perc_misclassified) ])\n",
        "\n",
        "\n",
        "def sparse_setdiff(a1, a2):\n",
        "    a1a = a1.reshape(a1.shape[0], -1)\n",
        "    a2a = a2.reshape(a2.shape[0], -1)\n",
        "    spa2a = [np.where(x)[0].tolist() for x in a2a]\n",
        "    spa1a = [np.where(x)[0].tolist() for x in a1a]\n",
        "    idxs_to_keep = []\n",
        "    for idx, sample in enumerate(spa1a):\n",
        "        try:\n",
        "            spa2a.index(sample)\n",
        "        except ValueError:\n",
        "            # not in list\n",
        "            idxs_to_keep.append(idx)\n",
        "    return a1[idxs_to_keep], idxs_to_keep\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rFUtecuyVcM"
      },
      "source": [
        "class DNNFeatureMergeModel(HyperModel):\n",
        "    \n",
        "    def __init__(self, model_name, input_shape, num_classes):\n",
        "        self.input_shape = input_shape\n",
        "        self.num_classes = num_classes\n",
        "        self.model_name = model_name\n",
        "\n",
        "    def build(self, hp):\n",
        "        inputs = tf.keras.Input(shape=self.input_shape)\n",
        "        x = inputs\n",
        "        for idx, i in enumerate(range(hp.Int('dense_blocks_with_normalizations', 1, 10, default=1))):\n",
        "            if hp.Boolean(f'has_batchnormalization_{idx}', default=True):\n",
        "                x = BatchNormalization()(x)\n",
        "            x = Dense(units= hp.Choice(f'dense_block_nunits_{idx}', values=[16,32,64,128,256,512],default=128), \n",
        "                      activation=hp.Choice(f'dense_activation_{idx}',\n",
        "                                       values=['selu', 'gelu', 'elu', 'relu', 'tanh', 'linear'], default='relu'),\n",
        "                  kernel_initializer=hp.Choice(f'dense_kernel_init_{idx}',\n",
        "                                       values=['HeNormal', 'HeUniform','VarianceScaling', 'LecunNormal','LecunUniform', 'GlorotUniform', 'GlorotNormal', 'RandomNormal', 'Ones', 'Orthogonal'], default='RandomNormal'),\n",
        "                  bias_initializer='zeros',\n",
        "                  name=f'dense_{idx}')(x)\n",
        "            if hp.Boolean(f'has_leakyrelu_{idx}', default=True):\n",
        "                x = LeakyReLU()(x)\n",
        "            if hp.Boolean(f'has_dropout_{idx}', default=True):\n",
        "                x = Dropout(hp.Float(f'dense_dropout_value_{idx}',\n",
        "                                 min_value=0.0,\n",
        "                                 max_value=0.99,\n",
        "                                 step=0.025,\n",
        "                                 default=0.6\n",
        "                                 ), name=f\"dense_dropout_{idx}\")(x)\n",
        "        outputs = Dense(self.num_classes, activation='softmax', name=\"last_softmax\")(x)\n",
        "        model = tf.keras.Model(inputs, outputs, name=self.model_name)\n",
        "        if hp.Boolean('optimize_adam', default=True):\n",
        "            model.compile(\n",
        "                optimizer=tf.keras.optimizers.Adam(hp.Float('learning_rate', 1e-7, 0.5e-1, sampling='log')),\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "        else:\n",
        "            model.compile(\n",
        "                optimizer=hp.Choice('final_optimizer',\n",
        "                                    values=['adam', 'SGD', 'RMSprop', 'Adadelta', 'Nadam', 'Adamax', 'Adagrad'],\n",
        "                                    default='adam'),\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "        return model\n",
        "    \n",
        "\n",
        "class BatchSizeTuner(kt.tuners.Hyperband):\n",
        "   def run_trial(self, trial, *args, **kwargs):\n",
        "#     # You can add additional HyperParameters for preprocessing and custom training loops via overriding `run_trial`\n",
        "     kwargs['batch_size'] = trial.hyperparameters.Int('batch_size', 16, 256, step=32)\n",
        "     super(BatchSizeTuner, self).run_trial(trial, *args, **kwargs)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXaV9H9HGBj6"
      },
      "source": [
        "def model_combination(model_name, input_shape):\n",
        "    model = Sequential([\n",
        "        tf.keras.Input(shape=input_shape),\n",
        "        BatchNormalization(),\n",
        "        Dense(256, kernel_initializer='RandomNormal', bias_initializer='zeros'),\n",
        "        LeakyReLU(),\n",
        "        Dropout(0.6),\n",
        "        #GaussianNoise(0.1),\n",
        "        Dense(128, kernel_initializer='RandomNormal', bias_initializer='zeros', kernel_regularizer = tf.keras.regularizers.l1(1e-3)),\n",
        "        LeakyReLU(),\n",
        "        #Dense(32, kernel_initializer='RandomNormal', bias_initializer='zeros', kernel_regularizer = tf.keras.regularizers.l1(1e-2)),\n",
        "        #LeakyReLU(),\n",
        "        Dropout(0.6),\n",
        "        Dense(32, kernel_initializer='RandomNormal', bias_initializer='zeros', kernel_regularizer = tf.keras.regularizers.l1(1e-2)),\n",
        "        LeakyReLU(),\n",
        "        Dropout(0.5),\n",
        "        # Dense(128, kernel_initializer='RandomNormal', bias_initializer='zeros', kernel_regularizer = tf.keras.regularizers.l1(1e-2)),\n",
        "        # LeakyReLU(),\n",
        "        Dense(13, activation='softmax')\n",
        "    ], name=model_name)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VM12SQkLykKU"
      },
      "source": [
        "# 'new' data \n",
        "X_train_1000e, Y_train_1000e, X_test_1000e, Y_test_1000e, X_val_1000e, Y_val_1000e = getE2eData(is500=False,\n",
        "                                                                                                    include_secondary=False,\n",
        "                                                                                                    isColab=True)\n",
        "X_train_1000e_w2nd, Y_train_1000e_w2nd, X_test_1000e_w2nd, Y_test_1000e_w2nd, X_val_1000e_w2nd, Y_val_1000e_w2nd = getE2eData(is500=False, include_secondary=True, isColab=True)\n",
        "X_train_1000e_j2nd, Y_train_1000e_j2nd, X_test_1000e_j2nd, Y_test_1000e_j2nd, X_val_1000e_j2nd, Y_val_1000e_j2nd = getE2eDataJustSecondary(isColab=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRzhAOuY0B33",
        "outputId": "342431b0-de15-4654-8d5a-37f5ea89301b"
      },
      "source": [
        "print (X_train_1000e.shape)\n",
        "print (X_train_1000e_w2nd.shape)\n",
        "print (X_train_1000e_j2nd.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6858, 1000, 8)\n",
            "(6858, 1136, 12)\n",
            "(6858, 1000, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuiFwxcoziU9"
      },
      "source": [
        "    # merge into a new train:\n",
        "    X_new_train = np.concatenate( (X_train_1000e, X_val_1000e), axis=0 )\n",
        "    Y_new_train = np.concatenate( (Y_train_1000e, Y_val_1000e), axis=0 )    \n",
        "    \n",
        "    X_new_train_j2nd = np.concatenate( (X_train_1000e_j2nd, X_val_1000e_j2nd), axis=0 )\n",
        "    Y_new_train_j2nd = np.concatenate( (Y_train_1000e_j2nd, Y_val_1000e_j2nd), axis=0 )    \n",
        "\n",
        "    X_new_train_w2nd = np.concatenate( (X_train_1000e_w2nd, X_val_1000e_w2nd), axis=0 )\n",
        "    Y_new_train_w2nd = np.concatenate( (Y_train_1000e_w2nd, Y_val_1000e_w2nd), axis=0 )    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KSM_vupCcQf5",
        "outputId": "f840406b-5427-49cc-e981-4dda46192652"
      },
      "source": [
        "    # CNNs no secondary\n",
        "    mCNN1_1000 = load_model(\"./drive/MyDrive/data_papers/ncRNA/CNN_baseline_May16_e2e1000_256.h5\") # CNN on 256 1st dens\n",
        "    mCNN1_1000._name = \"cnn_merged_newdata_finalist_1\"\n",
        "\n",
        "    mCNN2_1000 = load_model(\"./drive/MyDrive/data_papers/ncRNA/CNN_baseline_May16_e2e.h5\")   # CNN on 128 1st dens\n",
        "    mCNN2_1000._name = \"cnn_merged_newdata_finalist_2\"\n",
        "    \n",
        "    mCNN_1000 = load_model(\"./drive/MyDrive/data_papers/ncRNA/cnn_noTest_20210516_model_445_0.998\")   # CNN on 128 1st dens\n",
        "    mCNN_1000._name = \"cnn_merged_newdata_colab_finalist\"\n",
        "    \n",
        "    mCNN_1000 = load_model(\"./drive/MyDrive/data_papers/ncRNA/cnn_noTest_20210516_model_445_0.998\")   # CNN on 128 1st dens\n",
        "    mCNN_1000._name = \"cnn_merged_newdata_colab_finalist\"\n",
        "\n",
        "    # RNN on the same data\n",
        "    RNN_1000 = load_model(\"./drive/MyDrive/data_papers/ncRNA/RNN_baseline_17May_180.h5\", custom_objects=SeqWeightedAttention.get_custom_objects())   # RNN on 180ep 1000 ts\n",
        "    RNN_1000._name = \"rnn_merged_newdata_colab_finalist\"\n",
        "\n",
        "    # CNN w/ secondary\n",
        "    mCNN_1000_w2nd = load_model(\"./drive/MyDrive/data_papers/ncRNA/CNN_baseline_May16_e2e_secondary.h5\", custom_objects=SeqWeightedAttention.get_custom_objects())\n",
        "    mCNN_1000_w2nd._name = \"cnn_merged_newdata_w_secondary_finalist\"\n",
        "\n",
        "    # CNN secondary only\n",
        "    mCNN_1000_j2nd = load_model(\"./drive/MyDrive/data_papers/ncRNA/cnn_j2nd_noTest_20210516_model_488_0.990\", custom_objects=SeqWeightedAttention.get_custom_objects())\n",
        "    mCNN_1000_j2nd._name = \"cnn_merged_newdata_j_secondary_finalist\"\n",
        "    \n",
        "    mCNN1_1000.evaluate(X_test_1000e, Y_test_1000e)  # 96.15% \n",
        "    mCNN2_1000.evaluate(X_test_1000e, Y_test_1000e)  # 95.80 %  \n",
        "    mCNN_1000.evaluate(X_test_1000e, Y_test_1000e)  # 95.57% \n",
        "    mCNN_1000_w2nd.evaluate(X_test_1000e_w2nd, Y_test_1000e_w2nd)  # 94.64 %\n",
        "    mCNN_1000_j2nd.evaluate(X_test_1000e_j2nd, Y_test_1000e_j2nd)  # 72.96 %\n",
        "    RNN_1000.evaluate(X_test_1000e, Y_test_1000e)  # 95.45 %"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer gru will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer gru will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer gru will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer gru_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer gru_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer gru_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "27/27 [==============================] - 17s 8ms/step - loss: 0.2015 - accuracy: 0.9615\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.2149 - accuracy: 0.9580\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 0.2126 - accuracy: 0.9557\n",
            "27/27 [==============================] - 0s 6ms/step - loss: 0.2043 - accuracy: 0.9464\n",
            "27/27 [==============================] - 0s 5ms/step - loss: 1.7761 - accuracy: 0.7296\n",
            "27/27 [==============================] - 33s 1s/step - loss: 0.2070 - accuracy: 0.9545\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.20696324110031128, 0.9545454382896423]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZX5glv1E0w2"
      },
      "source": [
        " #tf.keras.utils.plot_model(RNN_1000, show_shapes=True)  ## , to_file=\"C:/temp/test.png\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBTr_vs33xmj"
      },
      "source": [
        "    to_combine_last_layers_no2nd_j2nd = [\n",
        "        (mCNN1_1000, \"dense_26\", None),\n",
        "        (mCNN2_1000, \"dense_14\", None),\n",
        "        (mCNN_1000_j2nd,\"dense_5\", None)\n",
        "    ]\n",
        "\n",
        "    combined_models_no2nd_j2nd, data_train_ll_no2nd_j2nd, data_test_ll_no2nd_j2nd, data_access_ll_no2nd_j2nd = get_combined_features_from_models(\n",
        "        to_combine_last_layers_no2nd_j2nd,\n",
        "        [ X_new_train, X_new_train, X_new_train_j2nd],\n",
        "        [ Y_new_train, Y_new_train, Y_new_train_j2nd], \n",
        "        [ X_test_1000e, X_test_1000e, X_test_1000e_j2nd],\n",
        "        [ Y_test_1000e, Y_test_1000e, Y_test_1000e_j2nd],\n",
        "        reverse_one_hot=False)\n",
        "\n",
        "    to_combine_last_layers_no2nd_j2nd_rNo2nd = [\n",
        "        (mCNN1_1000, \"dense_26\", None),\n",
        "        (mCNN_1000_j2nd,\"dense_5\", None),\n",
        "        (RNN_1000,\"dense_3\", None)\n",
        "    ]\n",
        "\n",
        "    combined_models_no2nd_j2nd_rNo2nd, data_train_ll_no2nd_j2nd_rNo2nd, data_test_ll_no2nd_j2nd_rNo2nd, data_access_ll_no2nd_j2nd_rNo2nd = get_combined_features_from_models(\n",
        "        to_combine_last_layers_no2nd_j2nd_rNo2nd,\n",
        "        [ X_new_train, X_new_train_j2nd, X_new_train],\n",
        "        [ Y_new_train, Y_new_train_j2nd, Y_new_train], \n",
        "        [ X_test_1000e, X_test_1000e_j2nd, X_test_1000e],\n",
        "        [ Y_test_1000e, Y_test_1000e_j2nd, Y_test_1000e],\n",
        "        reverse_one_hot=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7tUUs1MSkyr"
      },
      "source": [
        "    to_combine_penul_layers_no2nd_j2nd = [\n",
        "        (mCNN1_1000, \"dense_25\", None),\n",
        "        (mCNN2_1000, \"dense_13\", None),\n",
        "        (mCNN_1000_j2nd,\"dense_4\", None)\n",
        "    ]\n",
        "\n",
        "    combined_models_penul_no2nd_j2nd, data_train_ll_penul_no2nd_j2nd, data_test_ll_penul_no2nd_j2nd, data_access_ll_penul_no2nd_j2nd = get_combined_features_from_models(\n",
        "        to_combine_penul_layers_no2nd_j2nd,\n",
        "        [ X_new_train, X_new_train, X_new_train_j2nd],\n",
        "        [ Y_new_train, Y_new_train, Y_new_train_j2nd], \n",
        "        [ X_test_1000e, X_test_1000e, X_test_1000e_j2nd],\n",
        "        [ Y_test_1000e, Y_test_1000e, Y_test_1000e_j2nd],\n",
        "        reverse_one_hot=False)\n",
        "\n",
        "    to_combine_penul_layers_no2nd_j2nd_rNo2nd = [\n",
        "        (mCNN1_1000, \"dense_25\", None),\n",
        "        (mCNN_1000_j2nd,\"dense_4\", None),\n",
        "        (RNN_1000,\"dense_2\", None)\n",
        "    ]\n",
        "\n",
        "    combined_models_penul_no2nd_j2nd_rNo2nd, data_train_ll_penul_no2nd_j2nd_rNo2nd, data_test_ll_penul_no2nd_j2nd_rNo2nd, data_access_ll_penul_no2nd_j2nd_rNo2nd = get_combined_features_from_models(\n",
        "        to_combine_penul_layers_no2nd_j2nd_rNo2nd,\n",
        "        [ X_new_train, X_new_train_j2nd, X_new_train],\n",
        "        [ Y_new_train, Y_new_train_j2nd, Y_new_train], \n",
        "        [ X_test_1000e, X_test_1000e_j2nd, X_test_1000e],\n",
        "        [ Y_test_1000e, Y_test_1000e_j2nd, Y_test_1000e],\n",
        "        reverse_one_hot=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIXl45RwsESg"
      },
      "source": [
        "    to_combine_last_layers_no2nd_rNo2nd = [\n",
        "        (mCNN1_1000, \"dense_26\", None),\n",
        "        (RNN_1000,\"dense_3\", None)\n",
        "    ]\n",
        "\n",
        "    combined_models_no2nd_rNo2nd, data_train_ll_no2nd_rNo2nd, data_test_ll_no2nd_rNo2nd, data_access_ll_no2nd_rNo2nd = get_combined_features_from_models(\n",
        "        to_combine_last_layers_no2nd_rNo2nd,\n",
        "        [ X_new_train, X_new_train],\n",
        "        [ Y_new_train,  Y_new_train], \n",
        "        [ X_test_1000e,  X_test_1000e],\n",
        "        [ Y_test_1000e,  Y_test_1000e],\n",
        "        reverse_one_hot=False)\n",
        "    \n",
        "    to_combine_penul_layers_no2nd_rNo2nd = [\n",
        "        (mCNN1_1000, \"dense_25\", None),\n",
        "        (RNN_1000,\"dense_2\", None)\n",
        "    ]\n",
        "\n",
        "    combined_models_no2nd_rNo2nd_penul, data_train_penul_no2nd_rNo2nd, data_test_penul_no2nd_rNo2nd, data_access_penul_no2nd_rNo2nd = get_combined_features_from_models(\n",
        "        to_combine_penul_layers_no2nd_rNo2nd,\n",
        "        [ X_new_train, X_new_train],\n",
        "        [ Y_new_train,  Y_new_train], \n",
        "        [ X_test_1000e,  X_test_1000e],\n",
        "        [ Y_test_1000e,  Y_test_1000e],\n",
        "        reverse_one_hot=False)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSHkb_YUl9Zu"
      },
      "source": [
        "    to_combine_last2_layers_no2nd_rNo2nd = [\n",
        "        (mCNN1_1000, \"dense_25\", None),\n",
        "        (mCNN1_1000, \"dense_26\", None),\n",
        "        (RNN_1000,\"dense_2\", None),\n",
        "        (RNN_1000,\"dense_3\", None)\n",
        "    ]\n",
        "\n",
        "    combined_models_last2_no2nd_rNo2nd, data_train_last2_no2nd_rNo2nd, data_test_last2_no2nd_rNo2nd, data_access_last2_no2nd_rNo2nd = get_combined_features_from_models(\n",
        "        to_combine_last2_layers_no2nd_rNo2nd,\n",
        "        [ X_new_train, X_new_train, X_new_train, X_new_train],\n",
        "        [ Y_new_train,  Y_new_train, Y_new_train,  Y_new_train], \n",
        "        [ X_test_1000e,  X_test_1000e, X_test_1000e,  X_test_1000e],\n",
        "        [ Y_test_1000e,  Y_test_1000e, Y_test_1000e,  Y_test_1000e],\n",
        "        reverse_one_hot=False)\n",
        "    \n",
        "    to_combine_last2_layers_no2nd_j2nd_rNo2nd = [\n",
        "        (mCNN1_1000, \"dense_25\", None),\n",
        "        (mCNN1_1000, \"dense_26\", None),\n",
        "        (mCNN_1000_j2nd,\"dense_4\", None),\n",
        "        (mCNN_1000_j2nd,\"dense_5\", None),\n",
        "        (RNN_1000,\"dense_2\", None),\n",
        "        (RNN_1000,\"dense_3\", None)\n",
        "    ]\n",
        "\n",
        "    combined_models_last2_no2nd_j2nd_rNo2nd, data_train_last2_no2nd_j2nd_rNo2nd, data_test_last2_no2nd_j2nd_rNo2nd, data_access_last2_no2nd_j2nd_rNo2nd = get_combined_features_from_models(\n",
        "        to_combine_last2_layers_no2nd_j2nd_rNo2nd,\n",
        "        [ X_new_train, X_new_train, X_new_train_j2nd, X_new_train_j2nd, X_new_train, X_new_train],\n",
        "        [ Y_new_train,  Y_new_train, Y_new_train_j2nd, Y_new_train_j2nd, Y_new_train, Y_new_train], \n",
        "        [ X_test_1000e,  X_test_1000e, X_test_1000e_j2nd, X_test_1000e_j2nd, X_test_1000e, X_test_1000e],\n",
        "        [ Y_test_1000e,  Y_test_1000e, Y_test_1000e_j2nd, Y_test_1000e_j2nd, Y_test_1000e, Y_test_1000e],\n",
        "        reverse_one_hot=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNznmg7fs-Vz"
      },
      "source": [
        "rcnn_combine_models_no2nd_rNo2nd = model_combination(\"combine_rcnns_no2nd_rNo2nd_into_dense\", data_train_ll_no2nd_rNo2nd[0][0].shape  )\n",
        "rcnn_combine_models_no2nd_rNo2nd.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])  \n",
        "callbacks_used_rcnn_combine_no2nd_rNo2nd = [ModelCheckpoint(f'{rcnn_combine_models_no2nd_rNo2nd.name}' + '_model_{epoch:03d}_{accuracy:0.3f}',\n",
        "                                            save_weights_only=False,\n",
        "                                            monitor='accuracy',\n",
        "                                            mode='max',\n",
        "                                            save_best_only=True),\n",
        "                    tf.keras.callbacks.EarlyStopping(patience=10)\n",
        "                    ]\n",
        "rcnn_combine_models_no2nd_rNo2nd.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "history_rcnn_combine_no2nd_rNo2nd = rcnn_combine_models_no2nd_rNo2nd.fit(data_train_ll_no2nd_rNo2nd[0], \n",
        "                                              data_train_ll_no2nd_rNo2nd[1][0], \n",
        "                                              callbacks=callbacks_used_rcnn_combine_no2nd_rNo2nd, \n",
        "                                              verbose=2, \n",
        "                                              epochs = 500, \n",
        "                                              batch_size=64)\n",
        "  \n",
        "rcnn_combine_models_no2nd_rNo2nd.evaluate(data_test_ll_no2nd_rNo2nd[0],data_test_ll_no2nd_rNo2nd[1][0]) # 96.39%"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GtnjjGRt_Yx"
      },
      "source": [
        "rcnn_combine_penul_models_no2nd_rNo2nd = model_combination(\"combine_rcnns_penul_no2nd_rNo2nd_into_dense\", data_train_penul_no2nd_rNo2nd[0][0].shape  )\n",
        "rcnn_combine_penul_models_no2nd_rNo2nd.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])  \n",
        "callbacks_used_rcnn_combine_penul_no2nd_rNo2nd = [ModelCheckpoint(f'{rcnn_combine_penul_models_no2nd_rNo2nd.name}' + '_model_{epoch:03d}_{accuracy:0.3f}',\n",
        "                                            save_weights_only=False,\n",
        "                                            monitor='accuracy',\n",
        "                                            mode='max',\n",
        "                                            save_best_only=True),\n",
        "                    tf.keras.callbacks.EarlyStopping(patience=10)\n",
        "                    ]\n",
        "rcnn_combine_penul_models_no2nd_rNo2nd.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "history_rcnn_combine_penul_no2nd_rNo2nd = rcnn_combine_penul_models_no2nd_rNo2nd.fit(data_train_penul_no2nd_rNo2nd[0], \n",
        "                                              data_train_penul_no2nd_rNo2nd[1][0], \n",
        "                                              callbacks=callbacks_used_rcnn_combine_penul_no2nd_rNo2nd, \n",
        "                                              verbose=2, \n",
        "                                              epochs = 500, \n",
        "                                              batch_size=64)\n",
        "  \n",
        "rcnn_combine_penul_models_no2nd_rNo2nd.evaluate(data_test_penul_no2nd_rNo2nd[0],data_test_penul_no2nd_rNo2nd[1][0]) # 97.20%"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rmtDF-jGHoq"
      },
      "source": [
        "cnn_combine_model = model_combination(\"combine_cnns_no2nd_j2nd_into_dense\", data_train_ll_no2nd_j2nd[0][0].shape  )\n",
        "cnn_combine_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])  \n",
        "callbacks_used_cnn_combine = [ModelCheckpoint(f'{cnn_combine_model.name}' + '_model_{epoch:03d}_{accuracy:0.3f}',\n",
        "                                            save_weights_only=False,\n",
        "                                            monitor='accuracy',\n",
        "                                            mode='max',\n",
        "                                            save_best_only=True),\n",
        "                    tf.keras.callbacks.EarlyStopping(patience=10)\n",
        "                    ]\n",
        "cnn_combine_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "history_cnn_combine = cnn_combine_model.fit(data_train_ll_no2nd_j2nd[0], \n",
        "                                              data_train_ll_no2nd_j2nd[1][0], \n",
        "                                              callbacks=callbacks_used_cnn_combine, \n",
        "                                              verbose=2, \n",
        "                                              epochs = 500, \n",
        "                                              batch_size=64)\n",
        "  \n",
        "cnn_combine_model.evaluate(data_test_ll_no2nd_j2nd[0],data_test_ll_no2nd_j2nd[1][0]) # 96.85%\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cw5iYRtPeRHK"
      },
      "source": [
        "rcnn_combine_model = model_combination(\"combine_rcnns_no2nd_j2nd_rNo2nd_into_dense\", data_train_ll_no2nd_j2nd_rNo2nd[0][0].shape  )\n",
        "rcnn_combine_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])  \n",
        "callbacks_used_rcnn_combine = [ModelCheckpoint(f'{rcnn_combine_model.name}' + '_model_{epoch:03d}_{accuracy:0.3f}',\n",
        "                                            save_weights_only=False,\n",
        "                                            monitor='accuracy',\n",
        "                                            mode='max',\n",
        "                                            save_best_only=True),\n",
        "                    tf.keras.callbacks.EarlyStopping(patience=10)\n",
        "                    ]\n",
        "rcnn_combine_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "history_rcnn_combine = rcnn_combine_model.fit(data_train_ll_no2nd_j2nd_rNo2nd[0], \n",
        "                                              data_train_ll_no2nd_j2nd_rNo2nd[1][0], \n",
        "                                              callbacks=callbacks_used_rcnn_combine, \n",
        "                                              verbose=2, \n",
        "                                              epochs = 500, \n",
        "                                              batch_size=64)\n",
        "  \n",
        "rcnn_combine_model.evaluate(data_test_ll_no2nd_j2nd_rNo2nd[0],data_test_ll_no2nd_j2nd_rNo2nd[1][0])  # 96.39%\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TAUWcoueV7N"
      },
      "source": [
        "cnn_penul_combine_model = model_combination(\"combine_cnns_penul_no2nd_j2nd_into_dense\", data_train_ll_no2nd_j2nd[0][0].shape  )\n",
        "cnn_penul_combine_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])  \n",
        "callbacks_used_cnn_combine_penul = [ModelCheckpoint(f'{cnn_penul_combine_model.name}' + '_model_{epoch:03d}_{accuracy:0.3f}',\n",
        "                                            save_weights_only=False,\n",
        "                                            monitor='accuracy',\n",
        "                                            mode='max',\n",
        "                                            save_best_only=True),\n",
        "                    tf.keras.callbacks.EarlyStopping(patience=10)\n",
        "                    ]\n",
        "cnn_penul_combine_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "history_cnn_penul_combine = cnn_penul_combine_model.fit(data_train_ll_no2nd_j2nd[0], \n",
        "                                              data_train_ll_no2nd_j2nd[1][0], \n",
        "                                              callbacks=callbacks_used_cnn_combine_penul, \n",
        "                                              verbose=2, \n",
        "                                              epochs = 500, \n",
        "                                              batch_size=64)\n",
        "  \n",
        "cnn_penul_combine_model.evaluate(data_test_ll_no2nd_j2nd[0],data_test_ll_no2nd_j2nd[1][0]) # 96.39%"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ierH9hNbL5s6"
      },
      "source": [
        "rcnn_penul_combine_model = model_combination(\"combine_rcnns_penul_no2nd_j2nd_rNo2nd_into_dense\", data_train_ll_penul_no2nd_j2nd_rNo2nd[0][0].shape  )\n",
        "rcnn_penul_combine_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])  \n",
        "callbacks_used_rcnn_combine_penul = [ModelCheckpoint(f'{rcnn_penul_combine_model.name}' + '_model_{epoch:03d}_{accuracy:0.3f}',\n",
        "                                            save_weights_only=False,\n",
        "                                            monitor='accuracy',\n",
        "                                            mode='max',\n",
        "                                            save_best_only=True),\n",
        "                    tf.keras.callbacks.EarlyStopping(patience=10)\n",
        "                    ]\n",
        "rcnn_penul_combine_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "history_rcnn_penul_combine = rcnn_penul_combine_model.fit(data_train_ll_penul_no2nd_j2nd_rNo2nd[0], \n",
        "                                              data_train_ll_penul_no2nd_j2nd_rNo2nd[1][0], \n",
        "                                              callbacks=callbacks_used_rcnn_combine_penul, \n",
        "                                              verbose=2, \n",
        "                                              epochs = 500, \n",
        "                                              batch_size=64)\n",
        "  \n",
        "rcnn_penul_combine_model.evaluate(data_test_ll_penul_no2nd_j2nd_rNo2nd[0],data_test_ll_penul_no2nd_j2nd_rNo2nd[1][0]) # 97.32%\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yAsf-IXAuUiD",
        "outputId": "1f5513c0-7234-49ee-82d8-a14435290d84"
      },
      "source": [
        "rcnn_last2_combine_model_no2nd_rNo2nd = model_combination(\"combine_rcnns_last2_no2nd_rNo2nd_into_dense\", data_train_last2_no2nd_rNo2nd[0][0].shape  )\n",
        "rcnn_last2_combine_model_no2nd_rNo2nd.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])  \n",
        "callbacks_used_rcnn_combine_last2_no2nd_rNo2nd = [ModelCheckpoint(f'{rcnn_last2_combine_model_no2nd_rNo2nd.name}' + '_model_{epoch:03d}_{accuracy:0.3f}',\n",
        "                                            save_weights_only=False,\n",
        "                                            monitor='accuracy',\n",
        "                                            mode='max',\n",
        "                                            save_best_only=True),\n",
        "                    tf.keras.callbacks.EarlyStopping(patience=10)\n",
        "                    ]\n",
        "rcnn_last2_combine_model_no2nd_rNo2nd.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "history_rcnn_combine_last2_no2nd_rNo2nd = rcnn_last2_combine_model_no2nd_rNo2nd.fit(data_train_last2_no2nd_rNo2nd[0], \n",
        "                                              data_train_last2_no2nd_rNo2nd[1][0], \n",
        "                                              callbacks=callbacks_used_rcnn_combine_last2_no2nd_rNo2nd, \n",
        "                                              verbose=2, \n",
        "                                              epochs = 500, \n",
        "                                              batch_size=64)\n",
        "  \n",
        "rcnn_last2_combine_model_no2nd_rNo2nd.evaluate(data_test_last2_no2nd_rNo2nd[0],data_test_last2_no2nd_rNo2nd[1][0]) # 97.32%"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "121/121 - 1s - loss: 2.9018 - accuracy: 0.8113\n",
            "INFO:tensorflow:Assets written to: combine_rcnns_last2_no2nd_rNo2nd_into_dense_model_001_0.811/assets\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 2/500\n",
            "121/121 - 0s - loss: 1.3755 - accuracy: 0.9567\n",
            "INFO:tensorflow:Assets written to: combine_rcnns_last2_no2nd_rNo2nd_into_dense_model_002_0.957/assets\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 3/500\n",
            "121/121 - 0s - loss: 0.9574 - accuracy: 0.9668\n",
            "INFO:tensorflow:Assets written to: combine_rcnns_last2_no2nd_rNo2nd_into_dense_model_003_0.967/assets\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 4/500\n",
            "121/121 - 0s - loss: 0.7702 - accuracy: 0.9742\n",
            "INFO:tensorflow:Assets written to: combine_rcnns_last2_no2nd_rNo2nd_into_dense_model_004_0.974/assets\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 5/500\n",
            "121/121 - 0s - loss: 0.6758 - accuracy: 0.9786\n",
            "INFO:tensorflow:Assets written to: combine_rcnns_last2_no2nd_rNo2nd_into_dense_model_005_0.979/assets\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 6/500\n",
            "121/121 - 0s - loss: 0.6144 - accuracy: 0.9804\n",
            "INFO:tensorflow:Assets written to: combine_rcnns_last2_no2nd_rNo2nd_into_dense_model_006_0.980/assets\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 7/500\n",
            "121/121 - 0s - loss: 0.5734 - accuracy: 0.9800\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 8/500\n",
            "121/121 - 0s - loss: 0.5266 - accuracy: 0.9844\n",
            "INFO:tensorflow:Assets written to: combine_rcnns_last2_no2nd_rNo2nd_into_dense_model_008_0.984/assets\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 9/500\n",
            "121/121 - 0s - loss: 0.5051 - accuracy: 0.9852\n",
            "INFO:tensorflow:Assets written to: combine_rcnns_last2_no2nd_rNo2nd_into_dense_model_009_0.985/assets\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 10/500\n",
            "121/121 - 0s - loss: 0.4845 - accuracy: 0.9854\n",
            "INFO:tensorflow:Assets written to: combine_rcnns_last2_no2nd_rNo2nd_into_dense_model_010_0.985/assets\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 11/500\n",
            "121/121 - 0s - loss: 0.4839 - accuracy: 0.9847\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 12/500\n",
            "121/121 - 0s - loss: 0.4641 - accuracy: 0.9851\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 13/500\n",
            "121/121 - 0s - loss: 0.4553 - accuracy: 0.9863\n",
            "INFO:tensorflow:Assets written to: combine_rcnns_last2_no2nd_rNo2nd_into_dense_model_013_0.986/assets\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 14/500\n",
            "121/121 - 0s - loss: 0.4389 - accuracy: 0.9879\n",
            "INFO:tensorflow:Assets written to: combine_rcnns_last2_no2nd_rNo2nd_into_dense_model_014_0.988/assets\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 15/500\n",
            "121/121 - 0s - loss: 0.4288 - accuracy: 0.9883\n",
            "INFO:tensorflow:Assets written to: combine_rcnns_last2_no2nd_rNo2nd_into_dense_model_015_0.988/assets\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 16/500\n",
            "121/121 - 0s - loss: 0.4260 - accuracy: 0.9856\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 17/500\n",
            "121/121 - 0s - loss: 0.4457 - accuracy: 0.9841\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 18/500\n",
            "121/121 - 0s - loss: 0.4451 - accuracy: 0.9838\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 19/500\n",
            "121/121 - 0s - loss: 0.4253 - accuracy: 0.9860\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 20/500\n",
            "121/121 - 0s - loss: 0.3970 - accuracy: 0.9876\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 21/500\n",
            "121/121 - 0s - loss: 0.3870 - accuracy: 0.9868\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 22/500\n",
            "121/121 - 0s - loss: 0.4121 - accuracy: 0.9860\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 23/500\n",
            "121/121 - 0s - loss: 0.4029 - accuracy: 0.9868\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 24/500\n",
            "121/121 - 0s - loss: 0.4455 - accuracy: 0.9835\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 25/500\n",
            "121/121 - 0s - loss: 0.4158 - accuracy: 0.9851\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 26/500\n",
            "121/121 - 0s - loss: 0.4025 - accuracy: 0.9847\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 27/500\n",
            "121/121 - 0s - loss: 0.3948 - accuracy: 0.9891\n",
            "INFO:tensorflow:Assets written to: combine_rcnns_last2_no2nd_rNo2nd_into_dense_model_027_0.989/assets\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 28/500\n",
            "121/121 - 0s - loss: 0.3737 - accuracy: 0.9872\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 29/500\n",
            "121/121 - 0s - loss: 0.3721 - accuracy: 0.9896\n",
            "INFO:tensorflow:Assets written to: combine_rcnns_last2_no2nd_rNo2nd_into_dense_model_029_0.990/assets\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 30/500\n",
            "121/121 - 0s - loss: 0.4187 - accuracy: 0.9830\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 31/500\n",
            "121/121 - 0s - loss: 0.4660 - accuracy: 0.9847\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 32/500\n",
            "121/121 - 0s - loss: 0.3867 - accuracy: 0.9891\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 33/500\n",
            "121/121 - 0s - loss: 0.4154 - accuracy: 0.9842\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 34/500\n",
            "121/121 - 0s - loss: 0.3778 - accuracy: 0.9895\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 35/500\n",
            "121/121 - 0s - loss: 0.3996 - accuracy: 0.9843\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 36/500\n",
            "121/121 - 0s - loss: 0.4451 - accuracy: 0.9830\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 37/500\n",
            "121/121 - 0s - loss: 0.4780 - accuracy: 0.9800\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 38/500\n",
            "121/121 - 0s - loss: 0.4191 - accuracy: 0.9863\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 39/500\n",
            "121/121 - 0s - loss: 0.3827 - accuracy: 0.9861\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 40/500\n",
            "121/121 - 0s - loss: 0.4012 - accuracy: 0.9851\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 41/500\n",
            "121/121 - 0s - loss: 0.3708 - accuracy: 0.9886\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 42/500\n",
            "121/121 - 0s - loss: 0.3907 - accuracy: 0.9877\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 43/500\n",
            "121/121 - 0s - loss: 0.3427 - accuracy: 0.9889\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 44/500\n",
            "121/121 - 0s - loss: 0.4344 - accuracy: 0.9824\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 45/500\n",
            "121/121 - 0s - loss: 0.4914 - accuracy: 0.9815\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 46/500\n",
            "121/121 - 0s - loss: 0.5634 - accuracy: 0.9760\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 47/500\n",
            "121/121 - 0s - loss: 0.5835 - accuracy: 0.9785\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 48/500\n",
            "121/121 - 0s - loss: 0.7826 - accuracy: 0.9728\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 49/500\n",
            "121/121 - 0s - loss: 0.9422 - accuracy: 0.9755\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 50/500\n",
            "121/121 - 0s - loss: 0.8961 - accuracy: 0.9829\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 51/500\n",
            "121/121 - 0s - loss: 0.7430 - accuracy: 0.9850\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 52/500\n",
            "121/121 - 0s - loss: 0.5546 - accuracy: 0.9890\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 53/500\n",
            "121/121 - 0s - loss: 0.4256 - accuracy: 0.9913\n",
            "INFO:tensorflow:Assets written to: combine_rcnns_last2_no2nd_rNo2nd_into_dense_model_053_0.991/assets\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 54/500\n",
            "121/121 - 0s - loss: 0.3539 - accuracy: 0.9944\n",
            "INFO:tensorflow:Assets written to: combine_rcnns_last2_no2nd_rNo2nd_into_dense_model_054_0.994/assets\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 55/500\n",
            "121/121 - 0s - loss: 0.3124 - accuracy: 0.9936\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 56/500\n",
            "121/121 - 0s - loss: 0.2829 - accuracy: 0.9961\n",
            "INFO:tensorflow:Assets written to: combine_rcnns_last2_no2nd_rNo2nd_into_dense_model_056_0.996/assets\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 57/500\n",
            "121/121 - 0s - loss: 0.2972 - accuracy: 0.9931\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 58/500\n",
            "121/121 - 0s - loss: 0.3222 - accuracy: 0.9891\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 59/500\n",
            "121/121 - 0s - loss: 0.3077 - accuracy: 0.9934\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 60/500\n",
            "121/121 - 0s - loss: 0.2815 - accuracy: 0.9948\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 61/500\n",
            "121/121 - 0s - loss: 0.3052 - accuracy: 0.9903\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 62/500\n",
            "121/121 - 0s - loss: 0.3977 - accuracy: 0.9821\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 63/500\n",
            "121/121 - 0s - loss: 0.7499 - accuracy: 0.9716\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 64/500\n",
            "121/121 - 0s - loss: 1.1594 - accuracy: 0.9734\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 65/500\n",
            "121/121 - 0s - loss: 1.1910 - accuracy: 0.9760\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 66/500\n",
            "121/121 - 0s - loss: 1.1098 - accuracy: 0.9838\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 67/500\n",
            "121/121 - 0s - loss: 0.9125 - accuracy: 0.9889\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 68/500\n",
            "121/121 - 0s - loss: 0.7139 - accuracy: 0.9898\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 69/500\n",
            "121/121 - 0s - loss: 0.5859 - accuracy: 0.9898\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 70/500\n",
            "121/121 - 0s - loss: 0.4641 - accuracy: 0.9912\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 71/500\n",
            "121/121 - 0s - loss: 0.3898 - accuracy: 0.9925\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 72/500\n",
            "121/121 - 0s - loss: 0.3349 - accuracy: 0.9948\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 73/500\n",
            "121/121 - 0s - loss: 0.3069 - accuracy: 0.9940\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 74/500\n",
            "121/121 - 0s - loss: 0.2987 - accuracy: 0.9936\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 75/500\n",
            "121/121 - 0s - loss: 0.2831 - accuracy: 0.9942\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 76/500\n",
            "121/121 - 0s - loss: 0.2643 - accuracy: 0.9957\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 77/500\n",
            "121/121 - 0s - loss: 0.2759 - accuracy: 0.9922\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 78/500\n",
            "121/121 - 0s - loss: 0.3028 - accuracy: 0.9918\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 79/500\n",
            "121/121 - 0s - loss: 0.2979 - accuracy: 0.9896\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 80/500\n",
            "121/121 - 0s - loss: 0.3166 - accuracy: 0.9913\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 81/500\n",
            "121/121 - 0s - loss: 0.2989 - accuracy: 0.9916\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 82/500\n",
            "121/121 - 0s - loss: 0.3222 - accuracy: 0.9890\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 83/500\n",
            "121/121 - 0s - loss: 0.5312 - accuracy: 0.9746\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 84/500\n",
            "121/121 - 0s - loss: 0.9694 - accuracy: 0.9679\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 85/500\n",
            "121/121 - 0s - loss: 1.0574 - accuracy: 0.9778\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 86/500\n",
            "121/121 - 0s - loss: 1.0780 - accuracy: 0.9781\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 87/500\n",
            "121/121 - 0s - loss: 0.9830 - accuracy: 0.9861\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 88/500\n",
            "121/121 - 0s - loss: 0.7998 - accuracy: 0.9882\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 89/500\n",
            "121/121 - 0s - loss: 0.7168 - accuracy: 0.9843\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 90/500\n",
            "121/121 - 0s - loss: 0.5899 - accuracy: 0.9903\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 91/500\n",
            "121/121 - 0s - loss: 0.4586 - accuracy: 0.9922\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 92/500\n",
            "121/121 - 0s - loss: 0.3882 - accuracy: 0.9925\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 93/500\n",
            "121/121 - 0s - loss: 0.3332 - accuracy: 0.9943\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 94/500\n",
            "121/121 - 0s - loss: 0.3032 - accuracy: 0.9933\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 95/500\n",
            "121/121 - 0s - loss: 0.2918 - accuracy: 0.9946\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 96/500\n",
            "121/121 - 0s - loss: 0.2683 - accuracy: 0.9953\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 97/500\n",
            "121/121 - 0s - loss: 0.2677 - accuracy: 0.9938\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 98/500\n",
            "121/121 - 0s - loss: 0.2679 - accuracy: 0.9942\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 99/500\n",
            "121/121 - 0s - loss: 0.2508 - accuracy: 0.9951\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 100/500\n",
            "121/121 - 0s - loss: 0.2546 - accuracy: 0.9939\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 101/500\n",
            "121/121 - 0s - loss: 0.2594 - accuracy: 0.9935\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 102/500\n",
            "121/121 - 0s - loss: 0.2995 - accuracy: 0.9903\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 103/500\n",
            "121/121 - 0s - loss: 0.3278 - accuracy: 0.9860\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 104/500\n",
            "121/121 - 0s - loss: 0.5357 - accuracy: 0.9778\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 105/500\n",
            "121/121 - 0s - loss: 1.0155 - accuracy: 0.9673\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 106/500\n",
            "121/121 - 0s - loss: 1.2660 - accuracy: 0.9760\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 107/500\n",
            "121/121 - 0s - loss: 1.2365 - accuracy: 0.9820\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 108/500\n",
            "121/121 - 0s - loss: 1.1069 - accuracy: 0.9860\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 109/500\n",
            "121/121 - 0s - loss: 0.9518 - accuracy: 0.9887\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 110/500\n",
            "121/121 - 0s - loss: 0.8550 - accuracy: 0.9852\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 111/500\n",
            "121/121 - 0s - loss: 0.7371 - accuracy: 0.9896\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 112/500\n",
            "121/121 - 0s - loss: 0.5974 - accuracy: 0.9882\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 113/500\n",
            "121/121 - 0s - loss: 0.4874 - accuracy: 0.9930\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 114/500\n",
            "121/121 - 0s - loss: 0.3876 - accuracy: 0.9933\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 115/500\n",
            "121/121 - 0s - loss: 0.3384 - accuracy: 0.9931\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 116/500\n",
            "121/121 - 0s - loss: 0.3051 - accuracy: 0.9948\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 117/500\n",
            "121/121 - 0s - loss: 0.2749 - accuracy: 0.9974\n",
            "INFO:tensorflow:Assets written to: combine_rcnns_last2_no2nd_rNo2nd_into_dense_model_117_0.997/assets\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 118/500\n",
            "121/121 - 0s - loss: 0.2729 - accuracy: 0.9951\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 119/500\n",
            "121/121 - 0s - loss: 0.2683 - accuracy: 0.9953\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 120/500\n",
            "121/121 - 0s - loss: 0.2771 - accuracy: 0.9926\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 121/500\n",
            "121/121 - 0s - loss: 0.2723 - accuracy: 0.9944\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 122/500\n",
            "121/121 - 0s - loss: 0.2717 - accuracy: 0.9938\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 123/500\n",
            "121/121 - 0s - loss: 0.2706 - accuracy: 0.9933\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 124/500\n",
            "121/121 - 0s - loss: 0.3382 - accuracy: 0.9886\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 125/500\n",
            "121/121 - 0s - loss: 0.3864 - accuracy: 0.9855\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 126/500\n",
            "121/121 - 0s - loss: 0.4939 - accuracy: 0.9782\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 127/500\n",
            "121/121 - 0s - loss: 0.8045 - accuracy: 0.9708\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 128/500\n",
            "121/121 - 0s - loss: 0.9640 - accuracy: 0.9790\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 129/500\n",
            "121/121 - 0s - loss: 0.9406 - accuracy: 0.9856\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 130/500\n",
            "121/121 - 0s - loss: 0.8594 - accuracy: 0.9857\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 131/500\n",
            "121/121 - 0s - loss: 0.7764 - accuracy: 0.9855\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 132/500\n",
            "121/121 - 0s - loss: 0.7039 - accuracy: 0.9863\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 133/500\n",
            "121/121 - 0s - loss: 0.5755 - accuracy: 0.9898\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 134/500\n",
            "121/121 - 0s - loss: 0.4618 - accuracy: 0.9922\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 135/500\n",
            "121/121 - 0s - loss: 0.3824 - accuracy: 0.9931\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 136/500\n",
            "121/121 - 0s - loss: 0.3165 - accuracy: 0.9947\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 137/500\n",
            "121/121 - 0s - loss: 0.2833 - accuracy: 0.9955\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 138/500\n",
            "121/121 - 0s - loss: 0.2732 - accuracy: 0.9944\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 139/500\n",
            "121/121 - 0s - loss: 0.2631 - accuracy: 0.9942\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 140/500\n",
            "121/121 - 0s - loss: 0.2866 - accuracy: 0.9920\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 141/500\n",
            "121/121 - 0s - loss: 0.2887 - accuracy: 0.9939\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 142/500\n",
            "121/121 - 0s - loss: 0.2893 - accuracy: 0.9924\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 143/500\n",
            "121/121 - 0s - loss: 0.3006 - accuracy: 0.9907\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 144/500\n",
            "121/121 - 0s - loss: 0.2945 - accuracy: 0.9924\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 145/500\n",
            "121/121 - 0s - loss: 0.2999 - accuracy: 0.9914\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 146/500\n",
            "121/121 - 0s - loss: 0.3360 - accuracy: 0.9883\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 147/500\n",
            "121/121 - 0s - loss: 0.3589 - accuracy: 0.9874\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 148/500\n",
            "121/121 - 0s - loss: 0.6124 - accuracy: 0.9710\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 149/500\n",
            "121/121 - 0s - loss: 1.1165 - accuracy: 0.9688\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 150/500\n",
            "121/121 - 0s - loss: 1.4795 - accuracy: 0.9762\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 151/500\n",
            "121/121 - 0s - loss: 1.4296 - accuracy: 0.9855\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 152/500\n",
            "121/121 - 0s - loss: 1.2820 - accuracy: 0.9872\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 153/500\n",
            "121/121 - 0s - loss: 1.1109 - accuracy: 0.9900\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 154/500\n",
            "121/121 - 0s - loss: 1.0026 - accuracy: 0.9908\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 155/500\n",
            "121/121 - 0s - loss: 0.8367 - accuracy: 0.9948\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 156/500\n",
            "121/121 - 0s - loss: 0.7463 - accuracy: 0.9899\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 157/500\n",
            "121/121 - 0s - loss: 0.6139 - accuracy: 0.9927\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 158/500\n",
            "121/121 - 0s - loss: 0.5435 - accuracy: 0.9904\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 159/500\n",
            "121/121 - 0s - loss: 0.4584 - accuracy: 0.9909\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 160/500\n",
            "121/121 - 0s - loss: 0.4005 - accuracy: 0.9909\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 161/500\n",
            "121/121 - 0s - loss: 0.3420 - accuracy: 0.9943\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 162/500\n",
            "121/121 - 0s - loss: 0.2948 - accuracy: 0.9953\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 163/500\n",
            "121/121 - 0s - loss: 0.2859 - accuracy: 0.9944\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 164/500\n",
            "121/121 - 0s - loss: 0.2820 - accuracy: 0.9930\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 165/500\n",
            "121/121 - 0s - loss: 0.2722 - accuracy: 0.9942\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 166/500\n",
            "121/121 - 0s - loss: 0.2715 - accuracy: 0.9934\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 167/500\n",
            "121/121 - 0s - loss: 0.2667 - accuracy: 0.9949\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 168/500\n",
            "121/121 - 0s - loss: 0.2650 - accuracy: 0.9936\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 169/500\n",
            "121/121 - 0s - loss: 0.2688 - accuracy: 0.9925\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 170/500\n",
            "121/121 - 0s - loss: 0.2957 - accuracy: 0.9920\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 171/500\n",
            "121/121 - 0s - loss: 0.3435 - accuracy: 0.9869\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 172/500\n",
            "121/121 - 0s - loss: 0.4228 - accuracy: 0.9847\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 173/500\n",
            "121/121 - 0s - loss: 0.5651 - accuracy: 0.9759\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 174/500\n",
            "121/121 - 0s - loss: 0.9111 - accuracy: 0.9725\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 175/500\n",
            "121/121 - 0s - loss: 0.9862 - accuracy: 0.9803\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 176/500\n",
            "121/121 - 0s - loss: 0.9492 - accuracy: 0.9848\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 177/500\n",
            "121/121 - 0s - loss: 0.8809 - accuracy: 0.9851\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 178/500\n",
            "121/121 - 0s - loss: 0.8032 - accuracy: 0.9868\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 179/500\n",
            "121/121 - 0s - loss: 0.7350 - accuracy: 0.9859\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 180/500\n",
            "121/121 - 0s - loss: 0.6239 - accuracy: 0.9877\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 181/500\n",
            "121/121 - 0s - loss: 0.5276 - accuracy: 0.9911\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 182/500\n",
            "121/121 - 0s - loss: 0.4374 - accuracy: 0.9899\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 183/500\n",
            "121/121 - 0s - loss: 0.3683 - accuracy: 0.9929\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 184/500\n",
            "121/121 - 0s - loss: 0.3105 - accuracy: 0.9953\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 185/500\n",
            "121/121 - 0s - loss: 0.2741 - accuracy: 0.9971\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 186/500\n",
            "121/121 - 0s - loss: 0.2582 - accuracy: 0.9949\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 187/500\n",
            "121/121 - 0s - loss: 0.2444 - accuracy: 0.9961\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 188/500\n",
            "121/121 - 0s - loss: 0.2372 - accuracy: 0.9957\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 189/500\n",
            "121/121 - 0s - loss: 0.2447 - accuracy: 0.9955\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 190/500\n",
            "121/121 - 0s - loss: 0.2609 - accuracy: 0.9933\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 191/500\n",
            "121/121 - 0s - loss: 0.3484 - accuracy: 0.9854\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 192/500\n",
            "121/121 - 0s - loss: 0.6041 - accuracy: 0.9723\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 193/500\n",
            "121/121 - 0s - loss: 0.9709 - accuracy: 0.9758\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 194/500\n",
            "121/121 - 0s - loss: 1.1467 - accuracy: 0.9800\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 195/500\n",
            "121/121 - 0s - loss: 1.0611 - accuracy: 0.9860\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 196/500\n",
            "121/121 - 0s - loss: 0.9986 - accuracy: 0.9852\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 197/500\n",
            "121/121 - 0s - loss: 0.8951 - accuracy: 0.9891\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 198/500\n",
            "121/121 - 0s - loss: 0.7705 - accuracy: 0.9901\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 199/500\n",
            "121/121 - 0s - loss: 0.6870 - accuracy: 0.9887\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 200/500\n",
            "121/121 - 0s - loss: 0.5762 - accuracy: 0.9909\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 201/500\n",
            "121/121 - 0s - loss: 0.4697 - accuracy: 0.9924\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 202/500\n",
            "121/121 - 0s - loss: 0.3839 - accuracy: 0.9940\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 203/500\n",
            "121/121 - 0s - loss: 0.3334 - accuracy: 0.9930\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 204/500\n",
            "121/121 - 0s - loss: 0.2959 - accuracy: 0.9960\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 205/500\n",
            "121/121 - 0s - loss: 0.2686 - accuracy: 0.9962\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 206/500\n",
            "121/121 - 0s - loss: 0.2619 - accuracy: 0.9949\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 207/500\n",
            "121/121 - 0s - loss: 0.2581 - accuracy: 0.9935\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 208/500\n",
            "121/121 - 0s - loss: 0.2702 - accuracy: 0.9934\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 209/500\n",
            "121/121 - 0s - loss: 0.2582 - accuracy: 0.9935\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 210/500\n",
            "121/121 - 0s - loss: 0.2618 - accuracy: 0.9946\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 211/500\n",
            "121/121 - 0s - loss: 0.2391 - accuracy: 0.9955\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 212/500\n",
            "121/121 - 0s - loss: 0.2553 - accuracy: 0.9936\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 213/500\n",
            "121/121 - 0s - loss: 0.3270 - accuracy: 0.9877\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 214/500\n",
            "121/121 - 0s - loss: 0.5226 - accuracy: 0.9772\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 215/500\n",
            "121/121 - 0s - loss: 0.8244 - accuracy: 0.9702\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 216/500\n",
            "121/121 - 0s - loss: 1.1161 - accuracy: 0.9749\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 217/500\n",
            "121/121 - 0s - loss: 1.0845 - accuracy: 0.9834\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 218/500\n",
            "121/121 - 0s - loss: 1.0134 - accuracy: 0.9865\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 219/500\n",
            "121/121 - 0s - loss: 0.9682 - accuracy: 0.9859\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 220/500\n",
            "121/121 - 0s - loss: 0.8482 - accuracy: 0.9907\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 221/500\n",
            "121/121 - 0s - loss: 0.7353 - accuracy: 0.9896\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 222/500\n",
            "121/121 - 0s - loss: 0.6173 - accuracy: 0.9914\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 223/500\n",
            "121/121 - 0s - loss: 0.5177 - accuracy: 0.9909\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 224/500\n",
            "121/121 - 0s - loss: 0.4172 - accuracy: 0.9926\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 225/500\n",
            "121/121 - 0s - loss: 0.3830 - accuracy: 0.9925\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 226/500\n",
            "121/121 - 0s - loss: 0.3150 - accuracy: 0.9947\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 227/500\n",
            "121/121 - 0s - loss: 0.2791 - accuracy: 0.9946\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 228/500\n",
            "121/121 - 0s - loss: 0.2682 - accuracy: 0.9948\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 229/500\n",
            "121/121 - 0s - loss: 0.2548 - accuracy: 0.9946\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 230/500\n",
            "121/121 - 0s - loss: 0.2438 - accuracy: 0.9959\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 231/500\n",
            "121/121 - 0s - loss: 0.2416 - accuracy: 0.9961\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 232/500\n",
            "121/121 - 0s - loss: 0.2595 - accuracy: 0.9935\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 233/500\n",
            "121/121 - 0s - loss: 0.2535 - accuracy: 0.9939\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 234/500\n",
            "121/121 - 0s - loss: 0.2614 - accuracy: 0.9936\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 235/500\n",
            "121/121 - 0s - loss: 0.2821 - accuracy: 0.9905\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 236/500\n",
            "121/121 - 0s - loss: 0.2682 - accuracy: 0.9942\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 237/500\n",
            "121/121 - 0s - loss: 0.3207 - accuracy: 0.9869\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 238/500\n",
            "121/121 - 0s - loss: 0.7219 - accuracy: 0.9701\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 239/500\n",
            "121/121 - 0s - loss: 1.1130 - accuracy: 0.9746\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 240/500\n",
            "121/121 - 0s - loss: 1.1900 - accuracy: 0.9813\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 241/500\n",
            "121/121 - 0s - loss: 1.1069 - accuracy: 0.9869\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 242/500\n",
            "121/121 - 0s - loss: 1.0397 - accuracy: 0.9855\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 243/500\n",
            "121/121 - 0s - loss: 0.9485 - accuracy: 0.9886\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 244/500\n",
            "121/121 - 0s - loss: 0.8558 - accuracy: 0.9883\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 245/500\n",
            "121/121 - 0s - loss: 0.7538 - accuracy: 0.9890\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 246/500\n",
            "121/121 - 0s - loss: 0.6806 - accuracy: 0.9869\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 247/500\n",
            "121/121 - 0s - loss: 0.5801 - accuracy: 0.9907\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 248/500\n",
            "121/121 - 0s - loss: 0.4882 - accuracy: 0.9892\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 249/500\n",
            "121/121 - 0s - loss: 0.4086 - accuracy: 0.9927\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 250/500\n",
            "121/121 - 0s - loss: 0.3296 - accuracy: 0.9951\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 251/500\n",
            "121/121 - 0s - loss: 0.2824 - accuracy: 0.9961\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 252/500\n",
            "121/121 - 0s - loss: 0.2754 - accuracy: 0.9946\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 253/500\n",
            "121/121 - 0s - loss: 0.2698 - accuracy: 0.9944\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 254/500\n",
            "121/121 - 0s - loss: 0.2555 - accuracy: 0.9961\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 255/500\n",
            "121/121 - 0s - loss: 0.2366 - accuracy: 0.9966\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 256/500\n",
            "121/121 - 0s - loss: 0.2359 - accuracy: 0.9955\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 257/500\n",
            "121/121 - 0s - loss: 0.2604 - accuracy: 0.9935\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 258/500\n",
            "121/121 - 0s - loss: 0.2912 - accuracy: 0.9904\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 259/500\n",
            "121/121 - 0s - loss: 0.2548 - accuracy: 0.9962\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 260/500\n",
            "121/121 - 0s - loss: 0.2461 - accuracy: 0.9948\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 261/500\n",
            "121/121 - 0s - loss: 0.2864 - accuracy: 0.9907\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 262/500\n",
            "121/121 - 0s - loss: 0.4249 - accuracy: 0.9815\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 263/500\n",
            "121/121 - 0s - loss: 0.9389 - accuracy: 0.9649\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 264/500\n",
            "121/121 - 0s - loss: 1.3107 - accuracy: 0.9778\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 265/500\n",
            "121/121 - 0s - loss: 1.2534 - accuracy: 0.9861\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 266/500\n",
            "121/121 - 0s - loss: 1.1203 - accuracy: 0.9907\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 267/500\n",
            "121/121 - 0s - loss: 0.9356 - accuracy: 0.9931\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 268/500\n",
            "121/121 - 0s - loss: 0.8363 - accuracy: 0.9909\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 269/500\n",
            "121/121 - 0s - loss: 0.7677 - accuracy: 0.9896\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 270/500\n",
            "121/121 - 0s - loss: 0.6811 - accuracy: 0.9886\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 271/500\n",
            "121/121 - 0s - loss: 0.6082 - accuracy: 0.9898\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 272/500\n",
            "121/121 - 0s - loss: 0.5349 - accuracy: 0.9887\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 273/500\n",
            "121/121 - 0s - loss: 0.4249 - accuracy: 0.9938\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 274/500\n",
            "121/121 - 0s - loss: 0.3546 - accuracy: 0.9931\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 275/500\n",
            "121/121 - 0s - loss: 0.3326 - accuracy: 0.9929\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 276/500\n",
            "121/121 - 0s - loss: 0.2893 - accuracy: 0.9956\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 277/500\n",
            "121/121 - 0s - loss: 0.2556 - accuracy: 0.9957\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 278/500\n",
            "121/121 - 0s - loss: 0.2470 - accuracy: 0.9951\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 279/500\n",
            "121/121 - 0s - loss: 0.2496 - accuracy: 0.9957\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 280/500\n",
            "121/121 - 0s - loss: 0.2234 - accuracy: 0.9982\n",
            "INFO:tensorflow:Assets written to: combine_rcnns_last2_no2nd_rNo2nd_into_dense_model_280_0.998/assets\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 281/500\n",
            "121/121 - 0s - loss: 0.2245 - accuracy: 0.9952\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 282/500\n",
            "121/121 - 0s - loss: 0.2666 - accuracy: 0.9926\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 283/500\n",
            "121/121 - 0s - loss: 0.3082 - accuracy: 0.9885\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 284/500\n",
            "121/121 - 0s - loss: 0.3673 - accuracy: 0.9876\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 285/500\n",
            "121/121 - 0s - loss: 0.3823 - accuracy: 0.9859\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 286/500\n",
            "121/121 - 0s - loss: 0.5741 - accuracy: 0.9781\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 287/500\n",
            "121/121 - 0s - loss: 0.7137 - accuracy: 0.9787\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 288/500\n",
            "121/121 - 0s - loss: 0.8304 - accuracy: 0.9780\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 289/500\n",
            "121/121 - 0s - loss: 0.8778 - accuracy: 0.9821\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 290/500\n",
            "121/121 - 0s - loss: 0.8568 - accuracy: 0.9838\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 291/500\n",
            "121/121 - 0s - loss: 0.7788 - accuracy: 0.9881\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 292/500\n",
            "121/121 - 0s - loss: 0.6630 - accuracy: 0.9898\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 293/500\n",
            "121/121 - 0s - loss: 0.5876 - accuracy: 0.9890\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 294/500\n",
            "121/121 - 0s - loss: 0.4696 - accuracy: 0.9918\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 295/500\n",
            "121/121 - 0s - loss: 0.3766 - accuracy: 0.9913\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 296/500\n",
            "121/121 - 0s - loss: 0.3059 - accuracy: 0.9957\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 297/500\n",
            "121/121 - 0s - loss: 0.2670 - accuracy: 0.9957\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 298/500\n",
            "121/121 - 0s - loss: 0.2524 - accuracy: 0.9968\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 299/500\n",
            "121/121 - 0s - loss: 0.2543 - accuracy: 0.9943\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 300/500\n",
            "121/121 - 0s - loss: 0.2541 - accuracy: 0.9949\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 301/500\n",
            "121/121 - 0s - loss: 0.2503 - accuracy: 0.9943\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 302/500\n",
            "121/121 - 0s - loss: 0.2486 - accuracy: 0.9940\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 303/500\n",
            "121/121 - 0s - loss: 0.2383 - accuracy: 0.9956\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 304/500\n",
            "121/121 - 0s - loss: 0.2811 - accuracy: 0.9892\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 305/500\n",
            "121/121 - 0s - loss: 0.3690 - accuracy: 0.9843\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 306/500\n",
            "121/121 - 0s - loss: 0.5332 - accuracy: 0.9764\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 307/500\n",
            "121/121 - 0s - loss: 0.8734 - accuracy: 0.9725\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 308/500\n",
            "121/121 - 0s - loss: 1.0929 - accuracy: 0.9765\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 309/500\n",
            "121/121 - 0s - loss: 1.1313 - accuracy: 0.9848\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 310/500\n",
            "121/121 - 0s - loss: 1.0672 - accuracy: 0.9876\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 311/500\n",
            "121/121 - 0s - loss: 0.9464 - accuracy: 0.9890\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 312/500\n",
            "121/121 - 0s - loss: 0.8352 - accuracy: 0.9911\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 313/500\n",
            "121/121 - 0s - loss: 0.7483 - accuracy: 0.9891\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 314/500\n",
            "121/121 - 0s - loss: 0.6524 - accuracy: 0.9908\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 315/500\n",
            "121/121 - 0s - loss: 0.5207 - accuracy: 0.9939\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 316/500\n",
            "121/121 - 0s - loss: 0.4444 - accuracy: 0.9914\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 317/500\n",
            "121/121 - 0s - loss: 0.3823 - accuracy: 0.9925\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 318/500\n",
            "121/121 - 0s - loss: 0.3207 - accuracy: 0.9940\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 319/500\n",
            "121/121 - 0s - loss: 0.3074 - accuracy: 0.9938\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 320/500\n",
            "121/121 - 0s - loss: 0.2886 - accuracy: 0.9929\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 321/500\n",
            "121/121 - 0s - loss: 0.2723 - accuracy: 0.9948\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 322/500\n",
            "121/121 - 0s - loss: 0.2514 - accuracy: 0.9948\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 323/500\n",
            "121/121 - 0s - loss: 0.2431 - accuracy: 0.9957\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 324/500\n",
            "121/121 - 0s - loss: 0.2302 - accuracy: 0.9966\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 325/500\n",
            "121/121 - 0s - loss: 0.2236 - accuracy: 0.9966\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 326/500\n",
            "121/121 - 0s - loss: 0.2448 - accuracy: 0.9927\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 327/500\n",
            "121/121 - 0s - loss: 0.2398 - accuracy: 0.9959\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 328/500\n",
            "121/121 - 0s - loss: 0.2391 - accuracy: 0.9927\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 329/500\n",
            "121/121 - 0s - loss: 0.3420 - accuracy: 0.9839\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 330/500\n",
            "121/121 - 0s - loss: 0.5757 - accuracy: 0.9750\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 331/500\n",
            "121/121 - 0s - loss: 0.9577 - accuracy: 0.9703\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 332/500\n",
            "121/121 - 0s - loss: 1.0534 - accuracy: 0.9817\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 333/500\n",
            "121/121 - 0s - loss: 0.9606 - accuracy: 0.9876\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 334/500\n",
            "121/121 - 0s - loss: 0.8574 - accuracy: 0.9873\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 335/500\n",
            "121/121 - 0s - loss: 0.8073 - accuracy: 0.9859\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 336/500\n",
            "121/121 - 0s - loss: 0.7623 - accuracy: 0.9864\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 337/500\n",
            "121/121 - 0s - loss: 0.6875 - accuracy: 0.9892\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 338/500\n",
            "121/121 - 0s - loss: 0.5821 - accuracy: 0.9899\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 339/500\n",
            "121/121 - 0s - loss: 0.4985 - accuracy: 0.9918\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 340/500\n",
            "121/121 - 0s - loss: 0.3933 - accuracy: 0.9934\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 341/500\n",
            "121/121 - 0s - loss: 0.3369 - accuracy: 0.9935\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 342/500\n",
            "121/121 - 0s - loss: 0.3037 - accuracy: 0.9935\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 343/500\n",
            "121/121 - 0s - loss: 0.2704 - accuracy: 0.9942\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 344/500\n",
            "121/121 - 0s - loss: 0.2486 - accuracy: 0.9960\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 345/500\n",
            "121/121 - 0s - loss: 0.2467 - accuracy: 0.9951\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 346/500\n",
            "121/121 - 0s - loss: 0.2417 - accuracy: 0.9951\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 347/500\n",
            "121/121 - 0s - loss: 0.2288 - accuracy: 0.9962\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 348/500\n",
            "121/121 - 0s - loss: 0.2300 - accuracy: 0.9960\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 349/500\n",
            "121/121 - 0s - loss: 0.2658 - accuracy: 0.9911\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 350/500\n",
            "121/121 - 0s - loss: 0.3005 - accuracy: 0.9912\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 351/500\n",
            "121/121 - 0s - loss: 0.2499 - accuracy: 0.9948\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 352/500\n",
            "121/121 - 0s - loss: 0.2948 - accuracy: 0.9899\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 353/500\n",
            "121/121 - 0s - loss: 0.4161 - accuracy: 0.9795\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 354/500\n",
            "121/121 - 0s - loss: 0.7199 - accuracy: 0.9754\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 355/500\n",
            "121/121 - 0s - loss: 1.0756 - accuracy: 0.9732\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 356/500\n",
            "121/121 - 0s - loss: 1.1405 - accuracy: 0.9809\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 357/500\n",
            "121/121 - 0s - loss: 1.1375 - accuracy: 0.9873\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 358/500\n",
            "121/121 - 0s - loss: 1.0240 - accuracy: 0.9881\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 359/500\n",
            "121/121 - 0s - loss: 0.9256 - accuracy: 0.9908\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 360/500\n",
            "121/121 - 0s - loss: 0.8528 - accuracy: 0.9883\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 361/500\n",
            "121/121 - 0s - loss: 0.7221 - accuracy: 0.9918\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 362/500\n",
            "121/121 - 0s - loss: 0.5934 - accuracy: 0.9924\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 363/500\n",
            "121/121 - 0s - loss: 0.4980 - accuracy: 0.9914\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 364/500\n",
            "121/121 - 0s - loss: 0.4368 - accuracy: 0.9922\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 365/500\n",
            "121/121 - 0s - loss: 0.3822 - accuracy: 0.9927\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 366/500\n",
            "121/121 - 0s - loss: 0.3293 - accuracy: 0.9943\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 367/500\n",
            "121/121 - 0s - loss: 0.2898 - accuracy: 0.9943\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 368/500\n",
            "121/121 - 0s - loss: 0.2671 - accuracy: 0.9952\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 369/500\n",
            "121/121 - 0s - loss: 0.2589 - accuracy: 0.9951\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 370/500\n",
            "121/121 - 0s - loss: 0.2465 - accuracy: 0.9948\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 371/500\n",
            "121/121 - 0s - loss: 0.2510 - accuracy: 0.9942\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 372/500\n",
            "121/121 - 0s - loss: 0.2415 - accuracy: 0.9965\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 373/500\n",
            "121/121 - 0s - loss: 0.2286 - accuracy: 0.9957\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 374/500\n",
            "121/121 - 0s - loss: 0.2359 - accuracy: 0.9949\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 375/500\n",
            "121/121 - 0s - loss: 0.2714 - accuracy: 0.9925\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 376/500\n",
            "121/121 - 0s - loss: 0.3279 - accuracy: 0.9905\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 377/500\n",
            "121/121 - 0s - loss: 0.2901 - accuracy: 0.9936\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 378/500\n",
            "121/121 - 0s - loss: 0.2805 - accuracy: 0.9903\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 379/500\n",
            "121/121 - 0s - loss: 0.3543 - accuracy: 0.9882\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 380/500\n",
            "121/121 - 0s - loss: 0.4884 - accuracy: 0.9797\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 381/500\n",
            "121/121 - 0s - loss: 1.0731 - accuracy: 0.9703\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 382/500\n",
            "121/121 - 0s - loss: 1.3755 - accuracy: 0.9830\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 383/500\n",
            "121/121 - 0s - loss: 1.2769 - accuracy: 0.9879\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 384/500\n",
            "121/121 - 0s - loss: 1.1990 - accuracy: 0.9904\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 385/500\n",
            "121/121 - 0s - loss: 1.1338 - accuracy: 0.9882\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 386/500\n",
            "121/121 - 0s - loss: 0.9933 - accuracy: 0.9917\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 387/500\n",
            "121/121 - 0s - loss: 0.8672 - accuracy: 0.9924\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 388/500\n",
            "121/121 - 0s - loss: 0.7234 - accuracy: 0.9920\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 389/500\n",
            "121/121 - 0s - loss: 0.6141 - accuracy: 0.9930\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 390/500\n",
            "121/121 - 0s - loss: 0.5168 - accuracy: 0.9922\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 391/500\n",
            "121/121 - 0s - loss: 0.4407 - accuracy: 0.9905\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 392/500\n",
            "121/121 - 0s - loss: 0.3693 - accuracy: 0.9955\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 393/500\n",
            "121/121 - 0s - loss: 0.3279 - accuracy: 0.9942\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 394/500\n",
            "121/121 - 0s - loss: 0.2843 - accuracy: 0.9959\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 395/500\n",
            "121/121 - 0s - loss: 0.2676 - accuracy: 0.9953\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 396/500\n",
            "121/121 - 0s - loss: 0.2514 - accuracy: 0.9961\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 397/500\n",
            "121/121 - 0s - loss: 0.2442 - accuracy: 0.9961\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 398/500\n",
            "121/121 - 0s - loss: 0.2482 - accuracy: 0.9943\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 399/500\n",
            "121/121 - 0s - loss: 0.2508 - accuracy: 0.9943\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 400/500\n",
            "121/121 - 0s - loss: 0.2753 - accuracy: 0.9940\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 401/500\n",
            "121/121 - 0s - loss: 0.2467 - accuracy: 0.9960\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 402/500\n",
            "121/121 - 0s - loss: 0.2478 - accuracy: 0.9951\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 403/500\n",
            "121/121 - 0s - loss: 0.2491 - accuracy: 0.9946\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 404/500\n",
            "121/121 - 0s - loss: 0.2782 - accuracy: 0.9925\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 405/500\n",
            "121/121 - 0s - loss: 0.3518 - accuracy: 0.9852\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 406/500\n",
            "121/121 - 0s - loss: 0.7790 - accuracy: 0.9667\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 407/500\n",
            "121/121 - 0s - loss: 1.2709 - accuracy: 0.9786\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 408/500\n",
            "121/121 - 0s - loss: 1.3181 - accuracy: 0.9850\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 409/500\n",
            "121/121 - 0s - loss: 1.2144 - accuracy: 0.9889\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 410/500\n",
            "121/121 - 0s - loss: 1.0576 - accuracy: 0.9931\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 411/500\n",
            "121/121 - 0s - loss: 0.9602 - accuracy: 0.9894\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 412/500\n",
            "121/121 - 0s - loss: 0.8806 - accuracy: 0.9890\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 413/500\n",
            "121/121 - 0s - loss: 0.8004 - accuracy: 0.9900\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 414/500\n",
            "121/121 - 0s - loss: 0.7177 - accuracy: 0.9907\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 415/500\n",
            "121/121 - 0s - loss: 0.6065 - accuracy: 0.9917\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 416/500\n",
            "121/121 - 0s - loss: 0.5030 - accuracy: 0.9927\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 417/500\n",
            "121/121 - 0s - loss: 0.4140 - accuracy: 0.9924\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 418/500\n",
            "121/121 - 0s - loss: 0.3359 - accuracy: 0.9940\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 419/500\n",
            "121/121 - 0s - loss: 0.2896 - accuracy: 0.9955\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 420/500\n",
            "121/121 - 0s - loss: 0.2623 - accuracy: 0.9982\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 421/500\n",
            "121/121 - 0s - loss: 0.2484 - accuracy: 0.9966\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 422/500\n",
            "121/121 - 0s - loss: 0.2470 - accuracy: 0.9956\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 423/500\n",
            "121/121 - 0s - loss: 0.2327 - accuracy: 0.9955\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 424/500\n",
            "121/121 - 0s - loss: 0.2392 - accuracy: 0.9946\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 425/500\n",
            "121/121 - 0s - loss: 0.2649 - accuracy: 0.9933\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 426/500\n",
            "121/121 - 0s - loss: 0.2764 - accuracy: 0.9925\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 427/500\n",
            "121/121 - 0s - loss: 0.2593 - accuracy: 0.9946\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 428/500\n",
            "121/121 - 0s - loss: 0.2523 - accuracy: 0.9936\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 429/500\n",
            "121/121 - 0s - loss: 0.2516 - accuracy: 0.9924\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 430/500\n",
            "121/121 - 0s - loss: 0.2747 - accuracy: 0.9909\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 431/500\n",
            "121/121 - 0s - loss: 0.5472 - accuracy: 0.9719\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 432/500\n",
            "121/121 - 0s - loss: 1.3277 - accuracy: 0.9714\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 433/500\n",
            "121/121 - 0s - loss: 1.4767 - accuracy: 0.9839\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 434/500\n",
            "121/121 - 0s - loss: 1.3202 - accuracy: 0.9903\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 435/500\n",
            "121/121 - 0s - loss: 1.1596 - accuracy: 0.9903\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 436/500\n",
            "121/121 - 0s - loss: 1.0514 - accuracy: 0.9891\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 437/500\n",
            "121/121 - 0s - loss: 0.9471 - accuracy: 0.9911\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 438/500\n",
            "121/121 - 0s - loss: 0.8301 - accuracy: 0.9922\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 439/500\n",
            "121/121 - 0s - loss: 0.6998 - accuracy: 0.9939\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 440/500\n",
            "121/121 - 0s - loss: 0.6229 - accuracy: 0.9925\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 441/500\n",
            "121/121 - 0s - loss: 0.5451 - accuracy: 0.9908\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 442/500\n",
            "121/121 - 0s - loss: 0.5187 - accuracy: 0.9883\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 443/500\n",
            "121/121 - 0s - loss: 0.4500 - accuracy: 0.9925\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 444/500\n",
            "121/121 - 0s - loss: 0.3540 - accuracy: 0.9938\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 445/500\n",
            "121/121 - 0s - loss: 0.2925 - accuracy: 0.9969\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 446/500\n",
            "121/121 - 0s - loss: 0.2639 - accuracy: 0.9960\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 447/500\n",
            "121/121 - 0s - loss: 0.2608 - accuracy: 0.9942\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 448/500\n",
            "121/121 - 0s - loss: 0.2546 - accuracy: 0.9931\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 449/500\n",
            "121/121 - 0s - loss: 0.2359 - accuracy: 0.9969\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 450/500\n",
            "121/121 - 0s - loss: 0.2259 - accuracy: 0.9960\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 451/500\n",
            "121/121 - 0s - loss: 0.2329 - accuracy: 0.9949\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 452/500\n",
            "121/121 - 0s - loss: 0.2367 - accuracy: 0.9966\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 453/500\n",
            "121/121 - 0s - loss: 0.2451 - accuracy: 0.9936\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 454/500\n",
            "121/121 - 0s - loss: 0.2615 - accuracy: 0.9904\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 455/500\n",
            "121/121 - 0s - loss: 0.2928 - accuracy: 0.9908\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 456/500\n",
            "121/121 - 0s - loss: 0.3223 - accuracy: 0.9874\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 457/500\n",
            "121/121 - 0s - loss: 0.5246 - accuracy: 0.9776\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 458/500\n",
            "121/121 - 0s - loss: 0.7508 - accuracy: 0.9771\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 459/500\n",
            "121/121 - 0s - loss: 0.9940 - accuracy: 0.9772\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 460/500\n",
            "121/121 - 0s - loss: 1.0681 - accuracy: 0.9831\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 461/500\n",
            "121/121 - 0s - loss: 0.9627 - accuracy: 0.9891\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 462/500\n",
            "121/121 - 0s - loss: 0.8707 - accuracy: 0.9889\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 463/500\n",
            "121/121 - 0s - loss: 0.7648 - accuracy: 0.9904\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 464/500\n",
            "121/121 - 0s - loss: 0.6750 - accuracy: 0.9907\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 465/500\n",
            "121/121 - 0s - loss: 0.5624 - accuracy: 0.9920\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 466/500\n",
            "121/121 - 0s - loss: 0.4515 - accuracy: 0.9927\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 467/500\n",
            "121/121 - 0s - loss: 0.3756 - accuracy: 0.9926\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 468/500\n",
            "121/121 - 0s - loss: 0.3166 - accuracy: 0.9933\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 469/500\n",
            "121/121 - 0s - loss: 0.2783 - accuracy: 0.9964\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 470/500\n",
            "121/121 - 0s - loss: 0.2739 - accuracy: 0.9943\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 471/500\n",
            "121/121 - 0s - loss: 0.2478 - accuracy: 0.9959\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 472/500\n",
            "121/121 - 0s - loss: 0.2268 - accuracy: 0.9968\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 473/500\n",
            "121/121 - 0s - loss: 0.2225 - accuracy: 0.9966\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 474/500\n",
            "121/121 - 0s - loss: 0.2278 - accuracy: 0.9956\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 475/500\n",
            "121/121 - 0s - loss: 0.2527 - accuracy: 0.9924\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 476/500\n",
            "121/121 - 0s - loss: 0.3333 - accuracy: 0.9886\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 477/500\n",
            "121/121 - 0s - loss: 0.3675 - accuracy: 0.9877\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 478/500\n",
            "121/121 - 0s - loss: 0.3316 - accuracy: 0.9918\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 479/500\n",
            "121/121 - 0s - loss: 0.3260 - accuracy: 0.9896\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 480/500\n",
            "121/121 - 0s - loss: 0.2741 - accuracy: 0.9952\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 481/500\n",
            "121/121 - 0s - loss: 0.2504 - accuracy: 0.9948\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 482/500\n",
            "121/121 - 0s - loss: 0.2637 - accuracy: 0.9920\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 483/500\n",
            "121/121 - 0s - loss: 0.3510 - accuracy: 0.9838\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 484/500\n",
            "121/121 - 0s - loss: 0.6214 - accuracy: 0.9733\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 485/500\n",
            "121/121 - 0s - loss: 1.2956 - accuracy: 0.9729\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 486/500\n",
            "121/121 - 0s - loss: 1.3589 - accuracy: 0.9866\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 487/500\n",
            "121/121 - 0s - loss: 1.2411 - accuracy: 0.9901\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 488/500\n",
            "121/121 - 0s - loss: 1.0958 - accuracy: 0.9920\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 489/500\n",
            "121/121 - 0s - loss: 0.9580 - accuracy: 0.9908\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 490/500\n",
            "121/121 - 0s - loss: 0.8782 - accuracy: 0.9901\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 491/500\n",
            "121/121 - 0s - loss: 0.7569 - accuracy: 0.9934\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 492/500\n",
            "121/121 - 0s - loss: 0.6175 - accuracy: 0.9917\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 493/500\n",
            "121/121 - 0s - loss: 0.5400 - accuracy: 0.9942\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 494/500\n",
            "121/121 - 0s - loss: 0.4597 - accuracy: 0.9918\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 495/500\n",
            "121/121 - 0s - loss: 0.3766 - accuracy: 0.9949\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 496/500\n",
            "121/121 - 0s - loss: 0.3300 - accuracy: 0.9939\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 497/500\n",
            "121/121 - 0s - loss: 0.2793 - accuracy: 0.9964\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 498/500\n",
            "121/121 - 0s - loss: 0.2501 - accuracy: 0.9966\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 499/500\n",
            "121/121 - 0s - loss: 0.2389 - accuracy: 0.9962\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "Epoch 500/500\n",
            "121/121 - 0s - loss: 0.2298 - accuracy: 0.9965\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4411 - accuracy: 0.9732\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.44105181097984314, 0.9731934666633606]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygNfy8BvwGxb"
      },
      "source": [
        "rcnn_last2_combine_model_no2nd_j2nd_rNo2nd = model_combination(\"combine_rcnns_last2_no2nd_j2nd_rNo2nd_into_dense\", data_train_last2_no2nd_j2nd_rNo2nd[0][0].shape  )\n",
        "rcnn_last2_combine_model_no2nd_j2nd_rNo2nd.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])  \n",
        "callbacks_used_rcnn_combine_last2_no2nd_j2nd_rNo2nd = [ModelCheckpoint(f'{rcnn_last2_combine_model_no2nd_j2nd_rNo2nd.name}' + '_model_{epoch:03d}_{accuracy:0.3f}',\n",
        "                                            save_weights_only=False,\n",
        "                                            monitor='accuracy',\n",
        "                                            mode='max',\n",
        "                                            save_best_only=True),\n",
        "                    tf.keras.callbacks.EarlyStopping(patience=10)\n",
        "                    ]\n",
        "rcnn_last2_combine_model_no2nd_j2nd_rNo2nd.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "history_rcnn_combine_last2_no2nd_j2nd_rNo2nd = rcnn_last2_combine_model_no2nd_j2nd_rNo2nd.fit(data_train_last2_no2nd_j2nd_rNo2nd[0], \n",
        "                                              data_train_last2_no2nd_j2nd_rNo2nd[1][0], \n",
        "                                              callbacks=callbacks_used_rcnn_combine_last2_no2nd_j2nd_rNo2nd, \n",
        "                                              verbose=2, \n",
        "                                              epochs = 500, \n",
        "                                              batch_size=64)\n",
        "  \n",
        "rcnn_last2_combine_model_no2nd_j2nd_rNo2nd.evaluate(data_test_last2_no2nd_j2nd_rNo2nd[0],data_test_last2_no2nd_j2nd_rNo2nd[1][0]) #"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LkXb0FnHpGF",
        "outputId": "31478fe0-70cb-433b-829a-6d4f1373a3ed"
      },
      "source": [
        "cnn_combine_model.evaluate(data_test_ll_no2nd_j2nd[0],data_test_ll_no2nd_j2nd[1][0]) # 96.85%\n",
        "rcnn_combine_model.evaluate(data_test_ll_no2nd_j2nd_rNo2nd[0],data_test_ll_no2nd_j2nd_rNo2nd[1][0]) # 96.39%\n",
        "cnn_penul_combine_model.evaluate(data_test_ll_no2nd_j2nd[0],data_test_ll_no2nd_j2nd[1][0]) # 96.39%\n",
        "rcnn_penul_combine_model.evaluate(data_test_ll_penul_no2nd_j2nd_rNo2nd[0],data_test_ll_penul_no2nd_j2nd_rNo2nd[1][0]) # 97.32%\n",
        "rcnn_combine_models_no2nd_rNo2nd.evaluate(data_test_ll_no2nd_rNo2nd[0],data_test_ll_no2nd_rNo2nd[1][0]) # 96.39%\n",
        "rcnn_combine_penul_models_no2nd_rNo2nd.evaluate(data_test_penul_no2nd_rNo2nd[0],data_test_penul_no2nd_rNo2nd[1][0]) # 97.20%\n",
        "rcnn_last2_combine_model_no2nd_rNo2nd.evaluate(data_test_last2_no2nd_rNo2nd[0],data_test_last2_no2nd_rNo2nd[1][0]) # 97.32%\n",
        "rcnn_last2_combine_model_no2nd_j2nd_rNo2nd.evaluate(data_test_last2_no2nd_j2nd_rNo2nd[0],data_test_last2_no2nd_j2nd_rNo2nd[1][0]) # 97.20%"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "27/27 [==============================] - 0s 2ms/step - loss: 1.2021 - accuracy: 0.9685\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4793 - accuracy: 0.9639\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1.0965 - accuracy: 0.9639\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 1.4012 - accuracy: 0.9732\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.9990 - accuracy: 0.9639\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.3775 - accuracy: 0.9720\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3774701952934265, 0.9720279574394226]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWoc0J2H0Bxt"
      },
      "source": [
        "# cnn_combine_model.save(\"merge_model_a.h5\")\n",
        "# rcnn_combine_model.save(\"merge_model_b.h5\")\n",
        "# cnn_penul_combine_model.save(\"merge_model_c.h5\")\n",
        "# rcnn_penul_combine_model.save(\"merge_model_d.h5\")\n",
        "# rcnn_combine_models_no2nd_rNo2nd.save(\"merge_model_e.h5\")\n",
        "# rcnn_combine_penul_models_no2nd_rNo2nd.save(\"merge_model_f.h5\")\n",
        "rcnn_last2_combine_model_no2nd_rNo2nd.save(\"merge_model_g.h5\")\n",
        "rcnn_last2_combine_model_no2nd_j2nd_rNo2nd.save(\"merge_model_h.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 16
        },
        "id": "CvKlUyHl0f0S",
        "outputId": "664d5fa3-ec96-4b3d-9eea-a115ea5de168"
      },
      "source": [
        "from google.colab import files\n",
        "# files.download(\"/content/merge_model_a.h5\")\n",
        "# files.download(\"/content/merge_model_b.h5\")\n",
        "# files.download(\"/content/merge_model_c.h5\")\n",
        "# files.download(\"/content/merge_model_d.h5\")\n",
        "# files.download(\"/content/merge_model_e.h5\")\n",
        "# files.download(\"/content/merge_model_f.h5\")\n",
        "files.download(\"/content/merge_model_g.h5\")\n",
        "files.download(\"/content/merge_model_h.h5\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_cf4e2142-c8e1-4925-affe-1fc62558c839\", \"merge_model_g.h5\", 988208)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_db3baf93-4808-4ba2-94d3-b7bd9ba423dc\", \"merge_model_h.h5\", 1226272)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-sH8rsE-2JcY",
        "outputId": "38e01c2c-e87c-419f-9f1c-309c23f7b236"
      },
      "source": [
        "DNN_1000_last2_combine_model_no2nd_rNo2nd = load_model(\"/content/combine_rcnns_last2_no2nd_rNo2nd_into_dense_model_280_0.998\")   \n",
        "DNN_1000_last2_combine_model_no2nd_rNo2nd.evaluate(data_test_last2_no2nd_rNo2nd[0],data_test_last2_no2nd_rNo2nd[1][0])\n",
        "\n",
        "DNN_1000_last2_combine_model_no2nd_j2nd_rNo2nd = load_model(\"/content/combine_rcnns_last2_no2nd_j2nd_rNo2nd_into_dense_model_355_0.998\")   \n",
        "DNN_1000_last2_combine_model_no2nd_j2nd_rNo2nd.evaluate(data_test_last2_no2nd_j2nd_rNo2nd[0],data_test_last2_no2nd_j2nd_rNo2nd[1][0])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "27/27 [==============================] - 0s 2ms/step - loss: 0.3887 - accuracy: 0.9709\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4387 - accuracy: 0.9744\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4386712908744812, 0.9743589758872986]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzGmsAFT4O9e",
        "outputId": "c575a17c-f1dd-4718-e809-ea3200ea8b12"
      },
      "source": [
        "# DNN_1000_last2_combine_model_no2nd_j2nd_rNo2nd.save(\"merge_model_h_best_during_fit.h5\")\n",
        "# files.download(\"/content/merge_model_h_best_during_fit.h5\")\n",
        "# DNN_1000_last2_combine_model_no2nd_j2nd_rNo2nd.history.history\n",
        "# rcnn_last2_combine_model_no2nd_rNo2nd.history.history"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGiH8Wwl339i"
      },
      "source": [
        "# hypermodel_lastlayers_merge_1 = DNNFeatureMergeModel(model_name=\"combine_last_layers_no2nd_j2nd\", input_shape=(data_train_ll_no2nd_j2nd[0].shape[1],), num_classes=data_train_ll_no2nd_j2nd[1][0].shape[-1] )\n",
        "hypermodel_lastlayers_merge_1 = DNNFeatureMergeModel(model_name=\"combine_best_into_DNN\", input_shape=(data_test_ll_penul_no2nd_j2nd_rNo2nd[0].shape[1],), num_classes=data_test_ll_penul_no2nd_j2nd_rNo2nd[1][0].shape[-1] )\n",
        "\n",
        "# tuner = BatchSizeTuner(\n",
        "#     hypermodel_lastlayers_merge_1,\n",
        "#     max_epochs=4,\n",
        "#     objective='loss',\n",
        "#     executions_per_trial=4,\n",
        "#     hyperband_iterations=6,\n",
        "#     seed=123,\n",
        "#     directory=f'{hypermodel_lastlayers_merge_1.model_name}_hyperband'\n",
        "# )\n",
        "\n",
        "# tuner.search(data_train_ll_no2nd_j2nd[0], data_train_ll_no2nd_j2nd[1][0],\n",
        "#              epochs=50,\n",
        "#              callbacks=[tf.keras.callbacks.EarlyStopping(patience=2)])\n",
        "\n",
        "tuner = BatchSizeTuner(\n",
        "    hypermodel_lastlayers_merge_1,\n",
        "    max_epochs=4,\n",
        "    objective='loss',\n",
        "    executions_per_trial=4,\n",
        "    hyperband_iterations=6,\n",
        "    seed=123,\n",
        "    directory=f'{hypermodel_lastlayers_merge_1.model_name}_hyperband'\n",
        ")\n",
        "\n",
        "tuner.search(data_train_ll_no2nd_j2nd_rNo2nd[0], data_train_ll_no2nd_j2nd_rNo2nd[1][0],\n",
        "             epochs=50,\n",
        "             callbacks=[tf.keras.callbacks.EarlyStopping(patience=2)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2EogtPah4JLc",
        "outputId": "785aedac-6af8-4039-9a73-b6bc3f3f6594"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trial 60 Complete [00h 00m 07s]\n",
            "loss: 1.4409853219985962\n",
            "\n",
            "Best loss So Far: 0.003907026839442551\n",
            "Total elapsed time: 00h 09m 55s\n",
            "INFO:tensorflow:Oracle triggered exit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aaw6v-2q4fiT"
      },
      "source": [
        "# Show a summary of the search\n",
        "tuner.results_summary()\n",
        "# Retrieve the best model.\n",
        "tuner.get_best_models()\n",
        "\n",
        "best_model = tuner.get_best_models(num_models=1)[0]\n",
        "# best_model.save(\"hypermodel_merge_3lastlayers_m1.h5\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-pmEiMW6EPY",
        "outputId": "0fdcf7a1-2694-4986-ae57-6939c3192fa9"
      },
      "source": [
        "predY = np.apply_along_axis(np.argmax, 1, best_model.predict(data_test_ll_no2nd_j2nd_rNo2nd[0]))\n",
        "trueY = np.apply_along_axis(np.argmax, 1, data_test_ll_no2nd_j2nd_rNo2nd[1][0])\n",
        "np.sum(predY==trueY)/predY.shape[-1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xfok3o8ZbxDH"
      },
      "source": [
        "best_models = tuner.get_best_models(num_models=50)\n",
        "for model in best_models:\n",
        "  model.evaluate(data_test_ll_no2nd_j2nd_rNo2nd[0], data_test_ll_no2nd_j2nd_rNo2nd[1][0])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}